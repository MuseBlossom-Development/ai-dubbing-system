import os
import sys
import gradio as gr
import threading
import json
import subprocess
import shutil
from pathlib import Path
from pydub import AudioSegment


# í™˜ê²½ ì„¤ì •
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# ëª¨ë“ˆí™”ëœ import
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'CosyVoice'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'CosyVoice', 'third_party'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'CosyVoice', 'third_party', 'Matcha-TTS'))

from config import load_vad_config, save_vad_config
from main_processor import start_processing_with_settings
from whisper_processor import generate_srt_only
from audio_processor import parse_srt_segments, merge_segments_preserve_timing
from speaker_diarization import test_speaker_diarization
from utils import log_message


def apply_lip_sync(video_path, audio_path, output_path, progress_callback=None):
    """
    MuseTalkì„ ì‚¬ìš©í•˜ì—¬ ë¦½ì‹±í¬ ì ìš©
    
    Args:
        video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
        audio_path: ë²ˆì—­ëœ ìŒì„± ê²½ë¡œ  
        output_path: ë¦½ì‹±í¬ ì ìš©ëœ ë¹„ë””ì˜¤ ì¶œë ¥ ê²½ë¡œ
        progress_callback: ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
        str: ê²°ê³¼ ë©”ì‹œì§€
    """
    try:
        if progress_callback:
            progress_callback(0.1, "MuseTalk ì¤€ë¹„ ì¤‘...")

        # MuseTalk ë””ë ‰í† ë¦¬ ê²½ë¡œ
        musetalk_dir = os.path.join(os.path.dirname(__file__), 'MuseTalk')

        if not os.path.exists(musetalk_dir):
            return False, "MuseTalkì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."

        # ë¹„ë””ì˜¤ë¥¼ 25fpsë¡œ ë³€í™˜
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        temp_video_25fps = os.path.join(os.path.dirname(video_path), f"{base_name}_25fps.mp4")

        if progress_callback:
            progress_callback(0.2, "ë¹„ë””ì˜¤ë¥¼ 25fpsë¡œ ë³€í™˜ ì¤‘...")

        # FFmpegë¡œ 25fps ë³€í™˜
        ffmpeg_cmd = [
            "ffmpeg", "-y", "-i", video_path,
            "-r", "25", temp_video_25fps
        ]
        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)

        if result.returncode != 0:
            return False, f"ë¹„ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {result.stderr}"

        # MuseTalk ì„¤ì • íŒŒì¼ ìƒì„±
        config_dir = os.path.join(musetalk_dir, 'configs', 'inference')
        os.makedirs(config_dir, exist_ok=True)

        config_path = os.path.join(config_dir, 'lip_sync_config.yaml')

        # ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        rel_video_path = os.path.relpath(temp_video_25fps, musetalk_dir)
        rel_audio_path = os.path.relpath(audio_path, musetalk_dir)

        config_content = f"""task_0:
  video_path: "{rel_video_path}"
  audio_path: "{rel_audio_path}"
"""

        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)

        if progress_callback:
            progress_callback(0.3, "MuseTalk ì‹¤í–‰ ì¤‘... (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

        # MuseTalk ì‹¤í–‰
        musetalk_cmd = [
            "python", "-m", "scripts.inference",
            "--inference_config", "configs/inference/lip_sync_config.yaml",
            "--result_dir", "results/lip_sync",
            "--unet_model_path", "models/musetalkV15/unet.pth",
            "--unet_config", "models/musetalkV15/musetalk.json",
            "--version", "v15"
        ]

        # MuseTalk ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
        result = subprocess.run(
            musetalk_cmd,
            cwd=musetalk_dir,
            capture_output=True,
            text=True
        )

        if progress_callback:
            progress_callback(0.8, "ë¦½ì‹±í¬ ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")

        # ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        result_dir = os.path.join(musetalk_dir, 'results', 'lip_sync', 'v15')

        if not os.path.exists(result_dir):
            return False, f"MuseTalk ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result_dir}"

        # ìƒì„±ëœ íŒŒì¼ ì°¾ê¸°
        result_files = []
        for file in os.listdir(result_dir):
            if file.endswith('.mp4'):
                result_files.append(os.path.join(result_dir, file))

        if not result_files:
            return False, "ë¦½ì‹±í¬ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # ì²« ë²ˆì§¸ ê²°ê³¼ íŒŒì¼ì„ ì¶œë ¥ ê²½ë¡œë¡œ ë³µì‚¬
        shutil.copy2(result_files[0], output_path)

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(temp_video_25fps):
            os.remove(temp_video_25fps)

        if progress_callback:
            progress_callback(1.0, "ë¦½ì‹±í¬ ì™„ë£Œ!")

        return True, f"ë¦½ì‹±í¬ê°€ ì ìš©ëœ ë¹„ë””ì˜¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}"

    except Exception as e:
        return False, f"ë¦½ì‹±í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def update_vad_config(threshold, min_speech_duration_ms, max_speech_duration_s, min_silence_duration_ms, speech_pad_ms):
    """VAD ì„¤ì • ì—…ë°ì´íŠ¸ í•¨ìˆ˜"""
    try:
        vad_config = {
            "threshold": float(threshold),
            "min_speech_duration_ms": int(min_speech_duration_ms),
            "max_speech_duration_s": float(max_speech_duration_s),
            "min_silence_duration_ms": int(min_silence_duration_ms),
            "speech_pad_ms": int(speech_pad_ms)
        }
        save_vad_config(vad_config)
        return f"âœ… VAD ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\n{json.dumps(vad_config, indent=2, ensure_ascii=False)}"
    except Exception as e:
        return f"âŒ VAD ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def load_current_vad_config():
    """í˜„ì¬ VAD ì„¤ì • ë¡œë“œ"""
    try:
        config = load_vad_config()
        return (
            config.get("threshold", 0.5),
            config.get("min_speech_duration_ms", 3900),
            config.get("max_speech_duration_s", 20.0),
            config.get("min_silence_duration_ms", 250),
            config.get("speech_pad_ms", 100)
        )
    except:
        return 0.5, 3900, 20.0, 250, 100


def process_audio_video(
        input_file,
        enable_instruct,
        manual_command,
        command_mode,
        length_handling,
        overlap_handling,
        max_extension,
        enable_english,
        enable_chinese,
        enable_japanese,
        translation_length,
        translation_quality,
        enable_smart_compression,
        enable_speaker_diarization,
        speaker_mode,
        num_speakers,
        enable_speaker_splitting,
        enable_3sec_extension,
        vad_threshold,
        vad_min_speech_duration_ms,
        vad_max_speech_duration_s,
        vad_min_silence_duration_ms,
        vad_speech_pad_ms,
        enable_lip_sync,
        progress=gr.Progress()
):
    """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜"""
    if not input_file:
        return "âŒ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."

    try:
        # VAD ì„¤ì • ì—…ë°ì´íŠ¸
        vad_config = {
            "threshold": float(vad_threshold),
            "min_speech_duration_ms": int(vad_min_speech_duration_ms),
            "max_speech_duration_s": float(vad_max_speech_duration_s),
            "min_silence_duration_ms": int(vad_min_silence_duration_ms),
            "speech_pad_ms": int(vad_speech_pad_ms)
        }
        save_vad_config(vad_config)

        # ì„¤ì • ìˆ˜ì§‘
        settings = {
            'enable_instruct': enable_instruct,
            'manual_command': manual_command if command_mode == 'manual' else None,
            'length_handling': length_handling,
            'overlap_handling': overlap_handling,
            'max_extension': int(max_extension),
            'selected_languages': [
                lang for lang, enabled in [
                    ('english', enable_english),
                    ('chinese', enable_chinese),
                    ('japanese', enable_japanese)
                ] if enabled
            ],
            'translation_length': float(translation_length),
            'quality_mode': translation_quality,
            'enable_smart_compression': enable_smart_compression,
            'enable_speaker_diarization': enable_speaker_diarization,
            'num_speakers': int(num_speakers) if speaker_mode == 'fixed' else None,
            'enable_speaker_splitting': enable_speaker_splitting,
            'enable_3sec_extension': enable_3sec_extension,
            'vocals_volume': 1.0,
            'background_volume': 0.8,
            'enable_lip_sync': enable_lip_sync
        }

        progress(0.1, desc="ì²˜ë¦¬ ì‹œì‘...")

        # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
        input_path = input_file.name if hasattr(input_file, 'name') else input_file

        progress(0.3, desc="ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘...")

        # ë©”ì¸ ì²˜ë¦¬ ì‹¤í–‰
        start_processing_with_settings(input_path, settings)

        progress(1.0, desc="ì²˜ë¦¬ ì™„ë£Œ!")

        # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ìƒì„±
        base_name = os.path.splitext(os.path.basename(input_path))[0]
        output_dir = os.path.join(os.getcwd(), 'split_audio', base_name)

        result_info = f"âœ… ì²˜ë¦¬ ì™„ë£Œ!\n\n"
        result_info += f"ğŸ“ ì¶œë ¥ í´ë”: {output_dir}\n"
        result_info += f"ğŸ¤ VAD ì„¤ì •: threshold={vad_threshold}, min_speech={vad_min_speech_duration_ms}ms\n"

        # ë¦½ì‹±í¬ í™œì„±í™” ì‹œ MuseTalk ê²°ê³¼ í™•ì¸
        if enable_lip_sync:
            musetalk_dir = os.path.join(os.path.dirname(__file__), 'MuseTalk')
            if os.path.exists(musetalk_dir):
                musetalk_output_dir = os.path.join(musetalk_dir, 'results', 'lip_sync', 'v15')
                if os.path.exists(musetalk_output_dir):
                    try:
                        musetalk_files = [f for f in os.listdir(musetalk_output_dir) if f.endswith('.mp4')]
                        if musetalk_files:
                            result_info += f"ğŸ¥ ë¦½ì‹±í¬ ê²°ê³¼ íŒŒì¼: {musetalk_files[0]}\n"
                    except (OSError, PermissionError):
                        # ë””ë ‰í† ë¦¬ ì ‘ê·¼ ì˜¤ë¥˜ ì‹œ ë¬´ì‹œ
                        pass

        # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸
        if os.path.exists(output_dir):
            files = os.listdir(output_dir)
            result_info += f"ğŸ“„ ìƒì„±ëœ íŒŒì¼ ê°œìˆ˜: {len(files)}ê°œ\n"

            # SRT íŒŒì¼ í™•ì¸
            srt_files = [f for f in files if f.endswith('.srt')]
            if srt_files:
                result_info += f"ğŸ“ SRT íŒŒì¼: {srt_files[0]}\n"

            # ìŒì„± í•©ì„± ê²°ê³¼ í™•ì¸
            cosy_dir = os.path.join(output_dir, 'cosy_output')
            if os.path.exists(cosy_dir):
                cosy_files = os.listdir(cosy_dir)
                result_info += f"ğŸµ í•©ì„± ìŒì„± íŒŒì¼: {len(cosy_files)}ê°œ\n"

        return result_info

    except Exception as e:
        return f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def generate_srt_only_func(input_file, progress=gr.Progress()):
    """SRTë§Œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    if not input_file:
        return "âŒ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."

    try:
        progress(0.1, desc="SRT ìƒì„± ì‹œì‘...")

        input_path = input_file.name if hasattr(input_file, 'name') else input_file

        progress(0.5, desc="Whisper ì²˜ë¦¬ ì¤‘...")

        # SRT ìƒì„± ì‹¤í–‰
        srt_worker = generate_srt_only(input_path)
        srt_worker()

        progress(1.0, desc="SRT ìƒì„± ì™„ë£Œ!")

        # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        base_name = os.path.splitext(os.path.basename(input_path))[0]
        output_dir = os.path.join(os.getcwd(), 'split_audio', base_name)
        srt_path = os.path.join(output_dir, f"{base_name}.srt")

        result_info = f"âœ… SRT ìƒì„± ì™„ë£Œ!\n\n"
        result_info += f"ğŸ“ ì¶œë ¥ í´ë”: {output_dir}\n"
        result_info += f"ğŸ“ SRT íŒŒì¼: {srt_path}\n"

        return result_info

    except Exception as e:
        return f"âŒ SRT ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def speaker_diarization_func(input_file, enable_speaker_diarization, speaker_mode, num_speakers,
                             progress=gr.Progress()):
    """í™”ì ë¶„ë¦¬ í•¨ìˆ˜"""
    if not input_file:
        return "âŒ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."

    try:
        progress(0.1, desc="í™”ì ë¶„ë¦¬ ì‹œì‘...")

        input_path = input_file.name if hasattr(input_file, 'name') else input_file

        settings = {
            'enable_speaker_diarization': enable_speaker_diarization,
            'speaker_mode': speaker_mode,
            'num_speakers': int(num_speakers) if speaker_mode == 'fixed' else None,
            'enable_speaker_splitting': False,
            'enable_3sec_extension': True,
        }

        progress(0.5, desc="í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì¤‘...")

        test_speaker_diarization(input_path, settings)

        progress(1.0, desc="í™”ì ë¶„ë¦¬ ì™„ë£Œ!")

        return "âœ… í™”ì ë¶„ë¦¬ ì™„ë£Œ!"

    except Exception as e:
        return f"âŒ í™”ì ë¶„ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def merge_segments_func(input_file, merge_indices, synthesis_type, progress=gr.Progress()):
    """ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© í•¨ìˆ˜"""
    if not input_file:
        return "âŒ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."

    if not merge_indices.strip():
        return "âŒ ë³‘í•©í•  ì„¸ê·¸ë¨¼íŠ¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    try:
        progress(0.1, desc="ë³‘í•© ì‹œì‘...")

        input_path = input_file.name if hasattr(input_file, 'name') else input_file
        base_name = os.path.splitext(os.path.basename(input_path))[0]
        output_dir = os.path.join(os.getcwd(), 'split_audio', base_name)

        # SRT íŒŒì¼ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ë¡œë“œ
        input_ext = os.path.splitext(input_path)[1]
        srt_path = os.path.join(output_dir, f"{base_name}{input_ext}.srt")

        if not os.path.exists(srt_path):
            return f"âŒ SRT íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {srt_path}"

        segments = parse_srt_segments(srt_path)

        # ì›ë³¸ ì˜¤ë””ì˜¤ ë¡œë“œ
        orig_audio = AudioSegment.from_file(input_path)
        orig_dur = len(orig_audio)

        # ì‚¬ìš©ì ì…ë ¥ íŒŒì‹±
        try:
            if merge_indices.lower() == 'all':
                selected_segments = segments
                merged_filename = f"{base_name}_{synthesis_type.lower()}_all_merged.wav"
            else:
                indices = json.loads(merge_indices)
                selected_segments = [segments[i - 1] for i in indices]
                merged_filename = f"{base_name}_{synthesis_type.lower()}_custom.wav"
        except (json.JSONDecodeError, IndexError, ValueError):
            return "âŒ ì˜ëª»ëœ ì„¸ê·¸ë¨¼íŠ¸ ë²ˆí˜¸ í˜•ì‹ì…ë‹ˆë‹¤. ì˜ˆ: [1,2,3] ë˜ëŠ” 'all'"

        progress(0.5, desc="ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì¤‘...")

        # ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ê²°ì •
        if synthesis_type == "Instruct2":
            source_dir = os.path.join(output_dir, 'cosy_output', 'instruct')
        else:  # Zero-shot
            source_dir = os.path.join(output_dir, 'cosy_output')

        merged_path = os.path.join(output_dir, merged_filename)

        # ë³‘í•© ì‹¤í–‰
        merge_segments_preserve_timing(
            selected_segments, orig_dur, source_dir, merged_path,
            length_handling="preserve",
            overlap_handling="fade",
            max_extension=50,
            enable_smart_compression=True
        )

        progress(1.0, desc="ë³‘í•© ì™„ë£Œ!")

        return f"âœ… ë³‘í•© ì™„ë£Œ!\nğŸ“ ì¶œë ¥ íŒŒì¼: {merged_path}"

    except Exception as e:
        return f"âŒ ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def create_interface():
    """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""

    # í˜„ì¬ VAD ì„¤ì • ë¡œë“œ
    default_vad_config = load_current_vad_config()

    with gr.Blocks(title="STT Voice Splitter - ì›¹ ì¸í„°í˜ì´ìŠ¤", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸµ STT Voice Splitter - ì›¹ ì¸í„°í˜ì´ìŠ¤")
        gr.Markdown("ìŒì„±/ì˜ìƒ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ, ìŒì„± í•©ì„±, ë‹¤êµ­ì–´ ë²ˆì—­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

        with gr.Tabs():
            # ë©”ì¸ ì²˜ë¦¬ íƒ­
            with gr.TabItem("ğŸ¬ ë©”ì¸ ì²˜ë¦¬"):
                with gr.Row():
                    with gr.Column(scale=1):
                        input_file = gr.File(
                            label="ğŸ“ ì…ë ¥ íŒŒì¼",
                            file_types=[".wav", ".mp3", ".mp4", ".avi", ".mkv", ".mov", ".wmv", ".flv"]
                        )

                        # Instruct2 ì„¤ì •
                        with gr.Group():
                            gr.Markdown("### ğŸ¯ Instruct2 ì„¤ì •")
                            enable_instruct = gr.Checkbox(label="Instruct2 í•©ì„± í™œì„±í™”", value=False)
                            command_mode = gr.Radio(
                                choices=["auto", "manual"],
                                value="auto",
                                label="ëª…ë ¹ì–´ ì„¤ì •"
                            )
                            manual_command = gr.Textbox(
                                label="ìˆ˜ë™ ëª…ë ¹ì–´",
                                value="ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´",
                                placeholder="ì˜ˆ: ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´"
                            )

                        # VAD ì„¤ì • ì¶”ê°€
                        with gr.Group():
                            gr.Markdown("### ğŸ¤ VAD (ìŒì„± í™œë™ ê°ì§€) ì„¤ì •")
                            vad_threshold = gr.Slider(
                                minimum=0.1,
                                maximum=1.0,
                                value=default_vad_config[0],
                                step=0.05,
                                label="VAD ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë¯¼ê°)"
                            )
                            vad_min_speech_duration_ms = gr.Slider(
                                minimum=500,
                                maximum=10000,
                                value=default_vad_config[1],
                                step=100,
                                label="ìµœì†Œ ìŒì„± ê¸¸ì´ (ms)"
                            )
                            vad_max_speech_duration_s = gr.Slider(
                                minimum=5.0,
                                maximum=60.0,
                                value=default_vad_config[2],
                                step=1.0,
                                label="ìµœëŒ€ ìŒì„± ê¸¸ì´ (ì´ˆ)"
                            )
                            vad_min_silence_duration_ms = gr.Slider(
                                minimum=50,
                                maximum=1000,
                                value=default_vad_config[3],
                                step=50,
                                label="ìµœì†Œ ë¬´ìŒ ê¸¸ì´ (ms)"
                            )
                            vad_speech_pad_ms = gr.Slider(
                                minimum=0,
                                maximum=500,
                                value=default_vad_config[4],
                                step=10,
                                label="ìŒì„± íŒ¨ë”© (ms)"
                            )

                            # VAD ì„¤ì • ì—…ë°ì´íŠ¸ ë²„íŠ¼
                            update_vad_btn = gr.Button("ğŸ’¾ VAD ì„¤ì • ì €ì¥", variant="secondary", size="sm")
                            vad_update_output = gr.Textbox(label="VAD ì„¤ì • ìƒíƒœ", lines=2, visible=False)

                            update_vad_btn.click(
                                fn=update_vad_config,
                                inputs=[vad_threshold, vad_min_speech_duration_ms, vad_max_speech_duration_s,
                                        vad_min_silence_duration_ms, vad_speech_pad_ms],
                                outputs=vad_update_output
                            ).then(
                                lambda: gr.update(visible=True),
                                outputs=vad_update_output
                            )

                        # íƒ€ì„ë¼ì¸ ì„¤ì •
                        with gr.Group():
                            gr.Markdown("### â° íƒ€ì„ë¼ì¸ & ê¸¸ì´ ì²˜ë¦¬")
                            length_handling = gr.Radio(
                                choices=["preserve", "fit"],
                                value="preserve",
                                label="í•©ì„± ìŒì„± ê¸¸ì´ ì²˜ë¦¬"
                            )
                            overlap_handling = gr.Radio(
                                choices=["fade", "cut"],
                                value="fade",
                                label="ì„¸ê·¸ë¨¼íŠ¸ ê²¹ì¹¨ ì²˜ë¦¬"
                            )
                            max_extension = gr.Slider(
                                minimum=10,
                                maximum=100,
                                value=50,
                                step=10,
                                label="ìµœëŒ€ í™•ì¥ìœ¨ (%)"
                            )
                            enable_lip_sync_checkbox = gr.Checkbox(label="ğŸ¥ ë¦½ì‹±í¬ í™œì„±í™”", value=True)

                    with gr.Column(scale=1):
                        # ë²ˆì—­ ì„¤ì •
                        with gr.Group():
                            gr.Markdown("### ğŸŒ ë‹¤êµ­ì–´ ë²ˆì—­ ì„¤ì •")
                            enable_english = gr.Checkbox(label="ğŸ‡ºğŸ‡¸ ì˜ì–´", value=True)
                            enable_chinese = gr.Checkbox(label="ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´", value=True)
                            enable_japanese = gr.Checkbox(label="ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´", value=True)
                            translation_length = gr.Slider(
                                minimum=0.5,
                                maximum=2.0,
                                value=1.0,
                                step=0.1,
                                label="ë²ˆì—­ ê¸¸ì´ ë¹„ìœ¨"
                            )
                            translation_quality = gr.Radio(
                                choices=["concise", "balanced", "accurate"],
                                value="accurate",
                                label="ë²ˆì—­ í’ˆì§ˆ ìš°ì„ ìˆœìœ„"
                            )

                        # ê¸°íƒ€ ì„¤ì •
                        with gr.Group():
                            gr.Markdown("### âš™ï¸ ê¸°íƒ€ ì„¤ì •")
                            enable_smart_compression = gr.Checkbox(label="ìŠ¤ë§ˆíŠ¸ ì••ì¶• í™œì„±í™”", value=True)
                            enable_speaker_diarization = gr.Checkbox(label="í™”ì ë¶„ë¦¬ í™œì„±í™”", value=False)
                            speaker_mode = gr.Radio(
                                choices=["auto", "fixed"],
                                value="auto",
                                label="í™”ì ìˆ˜ ì„¤ì •"
                            )
                            num_speakers = gr.Slider(
                                minimum=2,
                                maximum=10,
                                value=2,
                                step=1,
                                label="ê³ ì • í™”ì ìˆ˜"
                            )
                            enable_speaker_splitting = gr.Checkbox(label="í™”ì ê¸°ë°˜ ë¶„í•  í™œì„±í™”", value=False)
                            enable_3sec_extension = gr.Checkbox(label="3ì´ˆ í™•ì¥ í™œì„±í™”", value=True)

                process_btn = gr.Button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", variant="primary", size="lg")
                main_output = gr.Textbox(label="ğŸ“Š ì²˜ë¦¬ ê²°ê³¼", lines=10)

                process_btn.click(
                    fn=process_audio_video,
                    inputs=[
                        input_file, enable_instruct, manual_command, command_mode,
                        length_handling, overlap_handling, max_extension,
                        enable_english, enable_chinese, enable_japanese,
                        translation_length, translation_quality, enable_smart_compression,
                        enable_speaker_diarization, speaker_mode, num_speakers,
                        enable_speaker_splitting, enable_3sec_extension,
                        vad_threshold, vad_min_speech_duration_ms, vad_max_speech_duration_s,
                        vad_min_silence_duration_ms, vad_speech_pad_ms,
                        enable_lip_sync_checkbox
                    ],
                    outputs=main_output,
                    show_progress=True
                )

            # SRT ì „ìš© ìƒì„± íƒ­
            with gr.TabItem("ğŸ“ SRT ì „ìš© ìƒì„±"):
                srt_file = gr.File(
                    label="ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼",
                    file_types=[".wav", ".mp3"]
                )
                srt_btn = gr.Button("ğŸ“ SRT ìƒì„±", variant="primary")
                srt_output = gr.Textbox(label="ğŸ“Š SRT ìƒì„± ê²°ê³¼", lines=5)

                srt_btn.click(
                    fn=generate_srt_only_func,
                    inputs=srt_file,
                    outputs=srt_output,
                    show_progress=True
                )

            # í™”ì ë¶„ë¦¬ íƒ­
            with gr.TabItem("ğŸ—£ï¸ í™”ì ë¶„ë¦¬"):
                speaker_file = gr.File(
                    label="ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼",
                    file_types=[".wav", ".mp3"]
                )
                with gr.Row():
                    speaker_diarization_enable = gr.Checkbox(label="í™”ì ë¶„ë¦¬ í™œì„±í™”", value=True)
                    speaker_mode_dia = gr.Radio(
                        choices=["auto", "fixed"],
                        value="auto",
                        label="í™”ì ìˆ˜ ì„¤ì •"
                    )
                    num_speakers_dia = gr.Slider(
                        minimum=2,
                        maximum=10,
                        value=2,
                        step=1,
                        label="ê³ ì • í™”ì ìˆ˜"
                    )

                speaker_btn = gr.Button("ğŸ—£ï¸ í™”ì ë¶„ë¦¬ ì‹¤í–‰", variant="primary")
                speaker_output = gr.Textbox(label="ğŸ“Š í™”ì ë¶„ë¦¬ ê²°ê³¼", lines=5)

                speaker_btn.click(
                    fn=speaker_diarization_func,
                    inputs=[speaker_file, speaker_diarization_enable, speaker_mode_dia, num_speakers_dia],
                    outputs=speaker_output,
                    show_progress=True
                )

            # ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© íƒ­
            with gr.TabItem("ğŸ”— ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©"):
                merge_file = gr.File(
                    label="ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼ (ì›ë³¸ íŒŒì¼)",
                    file_types=[".wav", ".mp3", ".mp4"]
                )
                with gr.Row():
                    with gr.Column():
                        merge_indices = gr.Textbox(
                            label="ë³‘í•©í•  ì„¸ê·¸ë¨¼íŠ¸ ë²ˆí˜¸",
                            placeholder="ì˜ˆ: [1,2,3] ë˜ëŠ” 'all'",
                            info="JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ê±°ë‚˜ 'all'ë¡œ ì „ì²´ ë³‘í•©"
                        )
                        synthesis_type = gr.Radio(
                            choices=["Zero-shot", "Instruct2"],
                            value="Zero-shot",
                            label="í•©ì„± íƒ€ì…"
                        )

                merge_btn = gr.Button("ğŸ”— ë³‘í•© ì‹¤í–‰", variant="primary")
                merge_output = gr.Textbox(label="ğŸ“Š ë³‘í•© ê²°ê³¼", lines=5)

                merge_btn.click(
                    fn=merge_segments_func,
                    inputs=[merge_file, merge_indices, synthesis_type],
                    outputs=merge_output,
                    show_progress=True
                )

            # VAD ì„¤ì • ì „ìš© íƒ­ ì¶”ê°€
            with gr.TabItem("ğŸ¤ VAD ì„¤ì •"):
                gr.Markdown("## ğŸ¤ VAD (Voice Activity Detection) ì„¤ì •")
                gr.Markdown("ìŒì„± í™œë™ ê°ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ì—¬ ìŒì„± ë¶„í•  í’ˆì§ˆì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                with gr.Row():
                    with gr.Column():
                        vad_threshold_tab = gr.Slider(
                            minimum=0.1,
                            maximum=1.0,
                            value=default_vad_config[0],
                            step=0.05,
                            label="VAD ì„ê³„ê°’",
                            info="ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ìŒì„±ì„ ê°ì§€ (0.3-0.7 ê¶Œì¥)"
                        )
                        vad_min_speech_duration_ms_tab = gr.Slider(
                            minimum=500,
                            maximum=10000,
                            value=default_vad_config[1],
                            step=100,
                            label="ìµœì†Œ ìŒì„± ê¸¸ì´ (ms)",
                            info="ì´ë³´ë‹¤ ì§§ì€ ìŒì„±ì€ ë¬´ì‹œ"
                        )
                        vad_max_speech_duration_s_tab = gr.Slider(
                            minimum=5.0,
                            maximum=60.0,
                            value=default_vad_config[2],
                            step=1.0,
                            label="ìµœëŒ€ ìŒì„± ê¸¸ì´ (ì´ˆ)",
                            info="ì´ë³´ë‹¤ ê¸´ ìŒì„±ì€ ë¶„í• "
                        )

                    with gr.Column():
                        vad_min_silence_duration_ms_tab = gr.Slider(
                            minimum=50,
                            maximum=1000,
                            value=default_vad_config[3],
                            step=50,
                            label="ìµœì†Œ ë¬´ìŒ ê¸¸ì´ (ms)",
                            info="ìŒì„± ë¶„í• ì„ ìœ„í•œ ìµœì†Œ ë¬´ìŒ êµ¬ê°„"
                        )
                        vad_speech_pad_ms_tab = gr.Slider(
                            minimum=0,
                            maximum=500,
                            value=default_vad_config[4],
                            step=10,
                            label="ìŒì„± íŒ¨ë”© (ms)",
                            info="ìŒì„± ì•ë’¤ì— ì¶”ê°€í•  ì—¬ë°±"
                        )

                        # í”„ë¦¬ì…‹ ë²„íŠ¼ë“¤
                        with gr.Row():
                            preset_sensitive_btn = gr.Button("ğŸ” ë¯¼ê° ëª¨ë“œ", variant="secondary")
                            preset_balanced_btn = gr.Button("âš–ï¸ ê· í˜• ëª¨ë“œ", variant="secondary")
                            preset_conservative_btn = gr.Button("ğŸ›¡ï¸ ë³´ìˆ˜ì  ëª¨ë“œ", variant="secondary")

                save_vad_btn = gr.Button("ğŸ’¾ VAD ì„¤ì • ì €ì¥", variant="primary", size="lg")
                vad_output_tab = gr.Textbox(label="ğŸ“Š VAD ì„¤ì • ê²°ê³¼", lines=5)

                # í”„ë¦¬ì…‹ í•¨ìˆ˜ë“¤
                def set_sensitive_preset():
                    return 0.3, 1000, 15.0, 100, 50

                def set_balanced_preset():
                    return 0.5, 3000, 20.0, 250, 100

                def set_conservative_preset():
                    return 0.7, 5000, 30.0, 500, 200

                preset_sensitive_btn.click(
                    fn=set_sensitive_preset,
                    outputs=[vad_threshold_tab, vad_min_speech_duration_ms_tab, vad_max_speech_duration_s_tab,
                             vad_min_silence_duration_ms_tab, vad_speech_pad_ms_tab]
                )

                preset_balanced_btn.click(
                    fn=set_balanced_preset,
                    outputs=[vad_threshold_tab, vad_min_speech_duration_ms_tab, vad_max_speech_duration_s_tab,
                             vad_min_silence_duration_ms_tab, vad_speech_pad_ms_tab]
                )

                preset_conservative_btn.click(
                    fn=set_conservative_preset,
                    outputs=[vad_threshold_tab, vad_min_speech_duration_ms_tab, vad_max_speech_duration_s_tab,
                             vad_min_silence_duration_ms_tab, vad_speech_pad_ms_tab]
                )

                save_vad_btn.click(
                    fn=update_vad_config,
                    inputs=[vad_threshold_tab, vad_min_speech_duration_ms_tab, vad_max_speech_duration_s_tab,
                            vad_min_silence_duration_ms_tab, vad_speech_pad_ms_tab],
                    outputs=vad_output_tab
                )

        # ì‚¬ìš©ë²• ì•ˆë‚´
        with gr.Accordion("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´", open=False):
            gr.Markdown("""
            ## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
            
            1. **ë©”ì¸ ì²˜ë¦¬**: ìŒì„±/ì˜ìƒ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ, ìŒì„± í•©ì„±, ë‹¤êµ­ì–´ ë²ˆì—­ ìˆ˜í–‰
            2. **SRT ì „ìš© ìƒì„±**: ìŒì„± íŒŒì¼ì—ì„œ SRT ìë§‰ íŒŒì¼ë§Œ ìƒì„±
            3. **í™”ì ë¶„ë¦¬**: ì—¬ëŸ¬ í™”ìê°€ ìˆëŠ” ìŒì„±ì„ ë¶„ë¦¬í•˜ì—¬ ë¶„ì„
            4. **ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©**: ì²˜ë¦¬ëœ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ì„ íƒì ìœ¼ë¡œ ë³‘í•©
            5. **VAD ì„¤ì •**: ìŒì„± í™œë™ ê°ì§€ ë§¤ê°œë³€ìˆ˜ ì¡°ì •ìœ¼ë¡œ ë¶„í•  í’ˆì§ˆ ê°œì„ 
            
            ## ğŸ“ ì„¤ì • ê°€ì´ë“œ
            
            - **Instruct2**: ë” ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± í•©ì„±ì„ ìœ„í•œ ê³ ê¸‰ ëª¨ë“œ
            - **ê¸¸ì´ ì²˜ë¦¬**: í•©ì„±ëœ ìŒì„±ì˜ ê¸¸ì´ë¥¼ ì›ë³¸ì— ë§ì¶¤ ë˜ëŠ” ë³´ì¡´
            - **ë²ˆì—­ ì„¤ì •**: ì›í•˜ëŠ” ì–¸ì–´ë¡œ ë²ˆì—­ ë° ìŒì„± í•©ì„±
            - **í™”ì ë¶„ë¦¬**: ì—¬ëŸ¬ í™”ìê°€ ìˆëŠ” ìŒì„±ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
            - **VAD ì„¤ì •**: ìŒì„± ê°ì§€ ì„ê³„ê°’ ë° ê¸¸ì´ ì œí•œ ì¡°ì •
            - **ë¦½ì‹±í¬**: MuseTalkì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ì— ë¦½ì‹±í¬ ì ìš©
            
            ## ğŸ¤ VAD ì„¤ì • íŒ
            
            - **ë¯¼ê° ëª¨ë“œ**: ì‘ì€ ì†Œë¦¬ë„ ê°ì§€, ì§§ì€ ìŒì„± êµ¬ê°„ë„ ë³´ì¡´
            - **ê· í˜• ëª¨ë“œ**: ì¼ë°˜ì ì¸ ìš©ë„ì— ì í•©í•œ ê¸°ë³¸ ì„¤ì •
            - **ë³´ìˆ˜ì  ëª¨ë“œ**: ëª…í™•í•œ ìŒì„±ë§Œ ê°ì§€, ë…¸ì´ì¦ˆ ì œê±°ì— íš¨ê³¼ì 
            
            ## ğŸ”§ ë³‘í•© ë°©ë²•
            
            - íŠ¹ì • ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©: `[1,2,3,5]` (ì„¸ê·¸ë¨¼íŠ¸ 1,2,3,5ë²ˆ ë³‘í•©)
            - ì „ì²´ ë³‘í•©: `all` (ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©)
            """)

    return demo


if __name__ == "__main__":
    # Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
    demo = create_interface()

    # ì„œë²„ ì‹¤í–‰ (ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©)
    demo.launch(
        server_name="0.0.0.0",  # ëª¨ë“  IPì—ì„œ ì ‘ê·¼ í—ˆìš©
        server_port=7860,  # í¬íŠ¸ ë²ˆí˜¸
        share=False,  # ê³µê°œ ë§í¬ ìƒì„± ì—¬ë¶€
        debug=True,  # ë””ë²„ê·¸ ëª¨ë“œ
        show_error=True  # ì˜¤ë¥˜ í‘œì‹œ
    )
