import os
import sys
import tkinter as tk
from tkinter import ttk, filedialog, scrolledtext
import threading, platform, subprocess, queue, json, shutil, re

# PyTorch ë””ë°”ì´ìŠ¤ ì„¤ì • (CPU/CUDAë§Œ, MPS ì œì™¸)
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
# CUDA ë©”ëª¨ë¦¬ ìµœì í™”

def clear_mps_cache():
    """í˜¸í™˜ì„±ì„ ìœ„í•œ ë¹ˆ í•¨ìˆ˜ (MPS ì‚¬ìš© ì•ˆí•¨)"""
    import gc
    gc.collect()

# CosyVoice íŒ¨í‚¤ì§€ ë° ì˜ì¡´ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ì¶”ê°€
repo_root = os.path.dirname(__file__)
sys.path.insert(0, os.path.join(repo_root, 'CosyVoice'))
sys.path.insert(0, os.path.join(repo_root, 'CosyVoice', 'third_party'))
# sys.path.insert(0, os.path.join(repo_root, 'CosyVoice', 'third_party', 'matcha'))
sys.path.insert(0, os.path.join(repo_root, 'CosyVoice', 'third_party', 'Matcha-TTS'))
from batch_cosy import main as cosy_batch
from pydub import AudioSegment  # pip install pydub
from batch_translate import batch_translate, SUPPORTED_LANGUAGES
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

def merge_custom_callback():
    try:
        # load original segments and duration
        base = os.path.splitext(os.path.basename(input_file_var.get()))[0]
        input_ext = os.path.splitext(input_file_var.get())[1]  # .mp3 ë˜ëŠ” .wav ë“±
        out_dir = os.path.join(os.getcwd(), 'split_audio', base)
        srt_path = os.path.join(out_dir, f"{base}{input_ext}.srt")
        segments = parse_srt_segments(srt_path)
        # load original full audio directly from the input path
        input_path = input_file_var.get()
        orig_audio = AudioSegment.from_file(input_path)
        orig_dur = len(orig_audio)
        # parse user timings list
        timings = json.loads(merge_entry.get())
        # merge using only specified segments indices
        selected = [segments[i-1] for i in timings]

        # ì‚¬ìš©ìê°€ ì„ íƒí•œ í•©ì„± íƒ€ì…ì— ë”°ë¼ ì†ŒìŠ¤ í´ë” ê²°ì •
        synthesis_type = synthesis_type_var.get()
        if synthesis_type == "Instruct2":
            source_dir = os.path.join(out_dir, 'cosy_output', 'instruct')
            merged_filename = f"{base}_instruct_custom.wav"
        else:  # Zero-shot (ê¸°ë³¸ê°’)
            source_dir = os.path.join(out_dir, 'cosy_output')
            merged_filename = f"{base}_custom.wav"

        merged_path = os.path.join(out_dir, merged_filename)
        length_handling = length_handling_var.get()
        overlap_handling = overlap_handling_var.get()
        max_extension = int(max_extension_var.get())
        enable_smart_compression = enable_smart_compression_var.get()

        merge_segments_preserve_timing(selected, orig_dur, source_dir, merged_path,
                                       length_handling=length_handling,
                                       overlap_handling=overlap_handling,
                                       max_extension=max_extension,
                                       enable_smart_compression=enable_smart_compression)
        log_message(f"âœ… {synthesis_type} ì»¤ìŠ¤í…€ ë³‘í•© ì™„ë£Œ: {merged_filename}")
    except Exception as e:
        log_message(f"ë³‘í•© ì˜¤ë¥˜: {e}")

# ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì½œë°± í•¨ìˆ˜
def merge_all_segments_callback():
    try:
        base = os.path.splitext(os.path.basename(input_file_var.get()))[0]
        input_ext = os.path.splitext(input_file_var.get())[1]  # .mp3 ë˜ëŠ” .wav ë“±
        out_dir = os.path.join(os.getcwd(), 'split_audio', base)
        srt_path = os.path.join(out_dir, f"{base}{input_ext}.srt")
        segments = parse_srt_segments(srt_path)
        input_path = input_file_var.get()
        orig_audio = AudioSegment.from_file(input_path)
        original_duration_ms = len(orig_audio)

        # ì‚¬ìš©ìê°€ ì„ íƒí•œ í•©ì„± íƒ€ì…ì— ë”°ë¼ ì†ŒìŠ¤ í´ë” ê²°ì •
        synthesis_type = synthesis_type_var.get()
        if synthesis_type == "Instruct2":
            source_dir = os.path.join(out_dir, 'cosy_output', 'instruct')
            merged_filename = f"{base}_instruct_merged.wav"
        else:  # Zero-shot (ê¸°ë³¸ê°’)
            source_dir = os.path.join(out_dir, 'cosy_output')
            merged_filename = f"{base}_cosy_merged.wav"

        merged_path = os.path.join(out_dir, merged_filename)
        length_handling = length_handling_var.get()
        overlap_handling = overlap_handling_var.get()
        max_extension = int(max_extension_var.get())
        enable_smart_compression = enable_smart_compression_var.get()

        merge_segments_preserve_timing(segments, original_duration_ms, source_dir, merged_path,
                                       length_handling=length_handling,
                                       overlap_handling=overlap_handling,
                                       max_extension=max_extension,
                                       enable_smart_compression=enable_smart_compression)
        log_message(f"âœ… {synthesis_type} ê²°ê³¼ ë³‘í•© ì™„ë£Œ: {merged_filename}")
    except Exception as e:
        log_message(f"ì „ì²´ ë³‘í•© ì˜¤ë¥˜: {e}")

# ------------------------
# OS/í™˜ê²½ ì •ë³´ ë° ê²½ë¡œ ì²˜ë¦¬
# ------------------------
IS_WINDOWS = platform.system() == "Windows"
IS_MACOS = platform.system() == "Darwin"

def resource_path(relative_path):
    try:
        base_path = sys._MEIPASS
    except AttributeError:
        base_path = os.getcwd()
    if IS_WINDOWS and relative_path.endswith('whisper-cli'):
        relative_path += '.exe'
    return os.path.join(base_path, relative_path)


# SRTë§Œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€
def generate_srt_only():
    """SRT íŒŒì¼ë§Œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    # í”Œë«í¼ë³„ íŒŒì¼íƒ€ì… í˜•ì‹ ë¶„ê¸°ì²˜ë¦¬
    if IS_WINDOWS:
        filetypes = [
            ('Audio Files', '*.wav;*.mp3'),
            ('WAV files', '*.wav'),
            ('MP3 files', '*.mp3'),
            ('All files', '*.*')
        ]
    else:
        filetypes = [
            ('Audio Files', '*.wav *.mp3'),
            ('WAV files', '*.wav'),
            ('MP3 files', '*.mp3'),
            ('All files', '*.*')
        ]

    input_file = filedialog.askopenfilename(filetypes=filetypes)
    if not input_file:
        return

    base = os.path.splitext(os.path.basename(input_file))[0]
    out = os.path.join(os.getcwd(), 'split_audio', base)
    os.makedirs(out, exist_ok=True)

    load_config()

    def srt_worker():
        try:
            log_message('== SRT ì „ìš© ìƒì„± ì‹œì‘ ==')
            model_path, is_coreml = get_model_path()
            log_message(f'ì‚¬ìš© ëª¨ë¸: {model_path} (CoreML: {is_coreml})')

            whisper_cmd = [
                WHISPER_CLI,
                '--vad',
                '--vad-model', resource_path('whisper.cpp/models/ggml-silero-v5.1.2.bin'),
                '--vad-threshold', str(vad_config['threshold']),
                '--vad-min-speech-duration-ms', str(vad_config['min_speech_duration_ms']),
                '--vad-min-silence-duration-ms', str(vad_config['min_silence_duration_ms']),
                '--vad-max-speech-duration-s', str(vad_config['max_speech_duration_s']),
                '--vad-speech-pad-ms', str(vad_config['speech_pad_ms']),
                '-f', input_file,
                '-m', model_path,
                '--output-srt',
                '--language', 'ko',
            ]

            run_command_with_logging(whisper_cmd, cwd=os.path.dirname(input_file),
                                     description="SRT ì „ìš© ìƒì„±")

            # SRT íŒŒì¼ì„ ì¶œë ¥ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
            input_dir = os.path.dirname(input_file)
            moved = False
            for f in os.listdir(input_dir):
                if f.startswith(base) and f.lower().endswith('.srt'):
                    src_path = os.path.join(input_dir, f)
                    dst_path = os.path.join(out, f)
                    shutil.move(src_path, dst_path)
                    log_message(f'âœ… SRT íŒŒì¼ ìƒì„± ì™„ë£Œ: {dst_path}')
                    moved = True
                    break

            if not moved:
                log_message('âŒ SRT íŒŒì¼ ìƒì„± ì‹¤íŒ¨: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
            else:
                log_message('== SRT ì „ìš© ìƒì„± ì™„ë£Œ ==')

        except Exception as e:
            log_message(f'SRT ìƒì„± ì˜¤ë¥˜: {e}')

    threading.Thread(target=srt_worker, daemon=True).start()


# whisper-cli ê²½ë¡œ
if IS_WINDOWS:
    WHISPER_CLI = resource_path('whisper.cpp/build/bin/Release/whisper-cli')
    if not os.path.exists(WHISPER_CLI):
        WHISPER_CLI = resource_path('whisper.cpp/build/bin/whisper-cli')
else:
    WHISPER_CLI = resource_path('whisper.cpp/build/bin/whisper-cli')


# ëª¨ë¸ ê²½ë¡œ ì„¤ì • (OSë³„ ë¶„ê¸°)
def get_model_path():
    """OSì— ë”°ë¥¸ ì ì ˆí•œ ëª¨ë¸ ê²½ë¡œ ë°˜í™˜"""
    if IS_MACOS:
        # macOS: ë¨¼ì € CoreML ëª¨ë¸ í™•ì¸, ì—†ìœ¼ë©´ GGML ëª¨ë¸ ì‚¬ìš©
        coreml_path = resource_path('whisper.cpp/models/ggml-large-v3-turbo-encoder.mlmodelc')
        ggml_path = resource_path('whisper.cpp/models/ggml-large-v3-turbo.bin')

        if os.path.exists(coreml_path) and os.path.exists(ggml_path):
            # CoreML ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ê¸°ë³¸ GGML ëª¨ë¸ë„ í•„ìš”í•¨
            return ggml_path, True  # GGML ëª¨ë¸ ê²½ë¡œ ë°˜í™˜, CoreML ì‚¬ìš©
        elif os.path.exists(ggml_path):
            return ggml_path, False  # GGML ëª¨ë¸ë§Œ ì‚¬ìš©
        else:
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ëª¨ë¸ë¡œ fallback
            return resource_path('whisper.cpp/models/for-tests-ggml-base.bin'), False
    else:
        # Windows/Linux: GGML ëª¨ë¸ë§Œ ì‚¬ìš©
        ggml_path = resource_path('resources/ggml-large-v3-turbo.bin')
        if os.path.exists(ggml_path):
            return ggml_path, False
        else:
            # whisper.cpp/models ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
            return resource_path('whisper.cpp/models/ggml-large-v3-turbo.bin'), False


# ffmpeg íƒìƒ‰
ffmpeg_path = shutil.which("ffmpeg")
if not ffmpeg_path and IS_WINDOWS:
    candidate = os.path.join(os.environ.get("CONDA_PREFIX",""), "Library", "bin", "ffmpeg.exe")
    if os.path.exists(candidate):
        ffmpeg_path = candidate
if not ffmpeg_path:
    raise RuntimeError("ffmpeg ì‹¤í–‰íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -------------------------------------
# VAD ì„¤ì • ë° ê¸°ë³¸ê°’
# -------------------------------------
CONFIG_FILE = 'vad_config.json'
DEFAULT_CONFIG = {
    'threshold': 0.6,
    'min_speech_duration_ms': 200,  # í…ŒìŠ¤íŠ¸ìš© ê°•ì œê°’
    'max_speech_duration_s': 15.0,
    'min_silence_duration_ms': 70,
    'speech_pad_ms': 0,  # íŒ¨ë”©ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ íƒ€ì„ë¼ì¸ ë™ê¸°í™” ê°œì„ 
}

install_log_queue = queue.Queue()
audio_log_queue   = queue.Queue()
vad_config        = {}


def log_message(message, also_print=True):
    """GUIì™€ í„°ë¯¸ë„ì— ë™ì¼í•œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥"""
    install_log_queue.put(message)
    if also_print:
        print(f"[LOG] {message}")


def audio_log_message(message, also_print=True):
    """ì˜¤ë””ì˜¤ ë¡œê·¸ë¥¼ GUIì™€ í„°ë¯¸ë„ì— ë™ì¼í•˜ê²Œ ì¶œë ¥"""
    audio_log_queue.put(message)
    if also_print:
        print(f"[AUDIO] {message}")


def run_command_with_logging(cmd, cwd=None, description="ëª…ë ¹ ì‹¤í–‰"):
    """ëª…ë ¹ì–´ ì‹¤í–‰ê³¼ ë™ì‹œì— ëª¨ë“  ì¶œë ¥ì„ ë¡œê·¸ë¡œ ì „ë‹¬"""
    log_message(f"{description}: {' '.join(cmd) if isinstance(cmd, list) else cmd}")

    try:
        process = subprocess.Popen(
            cmd,
            cwd=cwd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # stderrë„ stdoutìœ¼ë¡œ í•©ì¹˜ê¸°
            encoding='utf-8',
            errors='ignore',
            universal_newlines=True,
            bufsize=1
        )

        # ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ ì½ê¸°
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                line = output.strip()
                if line:  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ë¡œê·¸
                    log_message(line)

        return_code = process.poll()
        log_message(f"{description} ì™„ë£Œ (return code: {return_code})")
        return return_code

    except Exception as e:
        log_message(f"{description} ì˜¤ë¥˜: {e}")
        return -1

# -------------------------------------
# ë¡œê·¸ ì²˜ë¦¬
# -------------------------------------
def process_log_queue():
    """í†µí•© ë¡œê·¸ ì²˜ë¦¬ í•¨ìˆ˜"""
    while not install_log_queue.empty():
        line = install_log_queue.get()
        log_text.configure(state='normal')
        log_text.insert(tk.END, line + '\n')
        log_text.see(tk.END)
        log_text.configure(state='disabled')

    while not audio_log_queue.empty():
        line = audio_log_queue.get()
        log_text.configure(state='normal')
        log_text.insert(tk.END, f"[AUDIO] {line}" + '\n')
        log_text.see(tk.END)
        log_text.configure(state='disabled')

    root.after(200, process_log_queue)

# -------------------------------------
# SRT íŒŒì‹± ë° ì˜¤ë””ì˜¤ ë¶„í•  í•¨ìˆ˜
# -------------------------------------
_time_re = re.compile(r'(\d{2}:\d{2}:\d{2}[.,]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[.,]\d{3})')

def srt_time_to_milliseconds(t: str) -> int:
    t = t.replace(',', '.')
    h, m, rest = t.split(':')
    s, ms = rest.split('.')
    return (int(h)*3600 + int(m)*60 + int(s))*1000 + int(ms)

def parse_srt_segments(srt_path: str):
    segments = []
    with open(srt_path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            m = _time_re.search(line)
            if m:
                start, end = m.group(1), m.group(2)
                segments.append((srt_time_to_milliseconds(start),
                                 srt_time_to_milliseconds(end)))
    return segments

def split_audio_by_srt(audio_path: str, srt_path: str, output_dir: str):
    log_message(f'DEBUG: SRT ê²½ë¡œ â†’ {srt_path} / ì¡´ì¬ â†’ {os.path.exists(srt_path)}')
    segments = parse_srt_segments(srt_path)
    log_message(f'DEBUG: íŒŒì‹±ëœ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ â†’ {len(segments)}')

    audio = AudioSegment.from_file(audio_path)
    wav_folder = os.path.join(output_dir, 'wav')
    base = os.path.splitext(os.path.basename(audio_path))[0]
    os.makedirs(wav_folder, exist_ok=True)

    for idx, (start_ms, end_ms) in enumerate(segments, 1):
        chunk = audio[start_ms:end_ms]
        out_path = os.path.join(wav_folder, f"{base}_{idx:03d}.wav")
        chunk.export(out_path, format="wav")
        audio_log_message(f"ì„¸ê·¸ë¨¼íŠ¸ {idx}: {start_ms}~{end_ms}")
    return segments, len(audio)

# -------------------------------------
# ì¶”ê°€ ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ê¸¸ì´ ì¡°ì ˆ)
# -------------------------------------

def adjust_audio_speed(audio_segment, speed_factor):
    """
    ì˜¤ë””ì˜¤ ì†ë„ë¥¼ ì¡°ì ˆí•˜ë©´ì„œ í”¼ì¹˜ ë³´ì¡´
    Args:
        audio_segment: AudioSegment ê°ì²´
        speed_factor: ì†ë„ ë°°ìœ¨ (1.0 = ì›ë³¸, 1.2 = 20% ë¹ ë¥´ê²Œ)
    """
    try:
        # ì†ë„ ì¡°ì ˆ (í”„ë ˆì„ ë ˆì´íŠ¸ ë³€ê²½)
        adjusted = audio_segment._spawn(
            audio_segment.raw_data,
            overrides={"frame_rate": int(audio_segment.frame_rate * speed_factor)}
        ).set_frame_rate(audio_segment.frame_rate)
        return adjusted
    except Exception as e:
        log_message(f"ì†ë„ ì¡°ì ˆ ì˜¤ë¥˜: {e}")
        return audio_segment


def calculate_segment_priority(text_content, duration_ms):
    """
    ì„¸ê·¸ë¨¼íŠ¸ì˜ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
    Args:
        text_content: í…ìŠ¤íŠ¸ ë‚´ìš©
        duration_ms: ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ë°€ë¦¬ì´ˆ)
    Returns:
        priority_score: ì¤‘ìš”ë„ ì ìˆ˜ (0.0~1.0)
    """
    if not text_content:
        return 0.1  # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë‚®ì€ ìš°ì„ ìˆœìœ„

    # ê°„íˆ¬ì–´ ë° ë¶ˆí•„ìš” ìš”ì†Œ ê°ì§€
    filler_words = ['ìŒ', 'ì–´', 'ê·¸', 'ì €', 'ë­', 'ê·¸ëŸ°ë°', 'ê·¸ëŸ¬ë‹ˆê¹Œ']
    text_clean = text_content.strip().lower()

    # ê¸°ë³¸ ì ìˆ˜
    base_score = 0.5

    # ê¸¸ì´ ê¸°ë°˜ ë³´ì • (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ê²ƒì€ ìš°ì„ ìˆœìœ„ ë‚®ì¶¤)
    if duration_ms < 500:  # 0.5ì´ˆ ë¯¸ë§Œ
        base_score *= 0.7
    elif duration_ms > 10000:  # 10ì´ˆ ì´ˆê³¼
        base_score *= 0.8

    # ê°„íˆ¬ì–´ í¬í•¨ ì‹œ ìš°ì„ ìˆœìœ„ ë‚®ì¶¤
    filler_count = sum(1 for word in filler_words if word in text_clean)
    if filler_count > 0:
        base_score *= (0.8 ** filler_count)

    # ë¬¸ì¥ ë¶€í˜¸ ê¸°ë°˜ ì¤‘ìš”ë„ (ì™„ì „í•œ ë¬¸ì¥ì€ ë†’ì€ ìš°ì„ ìˆœìœ„)
    if any(punct in text_clean for punct in ['.', '!', '?', 'ë‹¤', 'ìš”', 'ë‹ˆë‹¤']):
        base_score *= 1.2

    # ì§§ì€ ê°íƒ„ì‚¬ë‚˜ ì‘ë‹µì€ ìš°ì„ ìˆœìœ„ ë‚®ì¶¤
    if len(text_clean) <= 3 and text_clean in ['ë„¤', 'ì˜ˆ', 'ì•„', 'ì˜¤', 'ì‘', 'ìŒ']:
        base_score *= 0.6

    return min(1.0, max(0.1, base_score))


def smart_audio_compression(audio_segment, target_duration_ms, text_content=""):
    """
    AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì˜¤ë””ì˜¤ ì••ì¶•
    Args:
        audio_segment: ì••ì¶•í•  ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸
        target_duration_ms: ëª©í‘œ ê¸¸ì´
        text_content: í…ìŠ¤íŠ¸ ë‚´ìš© (ìš°ì„ ìˆœìœ„ ê³„ì‚°ìš©)
    """
    current_duration = len(audio_segment)
    if current_duration <= target_duration_ms:
        return audio_segment

    compression_ratio = target_duration_ms / current_duration
    priority = calculate_segment_priority(text_content, current_duration)

    # ìˆ˜ì •ëœ ì˜¬ë°”ë¥¸ ë¡œì§: ì¤‘ìš”í•œ ë‚´ìš©ì€ ëœ ì••ì¶•, ë¶ˆí•„ìš”í•œ ë‚´ìš©ì€ ë” ì••ì¶•
    if priority >= 0.8:
        # ë†’ì€ ìš°ì„ ìˆœìœ„(ì¤‘ìš”í•œ ëŒ€ì‚¬): ìµœì†Œí•œì˜ ì••ì¶•ë§Œ (ì›ì†ë„ ìµœëŒ€í•œ ìœ ì§€)
        max_speed = min(1.05, 1.0 / compression_ratio)  # ìµœëŒ€ 5%ë§Œ ë¹ ë¥´ê²Œ
        return adjust_audio_speed(audio_segment, max_speed)

    elif priority >= 0.5:
        # ì¤‘ê°„ ìš°ì„ ìˆœìœ„: ì ë‹¹í•œ ì••ì¶•
        speed_factor = min(1.2, 1.0 / compression_ratio)  # ìµœëŒ€ 20% ë¹ ë¥´ê²Œ
        adjusted = adjust_audio_speed(audio_segment, speed_factor)

        # ì¶”ê°€ ì••ì¶•ì´ í•„ìš”í•œ ê²½ìš° ë¬´ìŒ êµ¬ê°„ ì••ì¶•
        if len(adjusted) > target_duration_ms:
            # ë¬´ìŒ êµ¬ê°„ íƒì§€ ë° ì••ì¶• (êµ¬í˜„ ê°„ì†Œí™”)
            remaining_ratio = target_duration_ms / len(adjusted)
            adjusted = adjust_audio_speed(adjusted, 1.0 / remaining_ratio)

        return adjusted

    else:
        # ë‚®ì€ ìš°ì„ ìˆœìœ„(ê°„íˆ¬ì–´, ê°íƒ„ì‚¬): ì ê·¹ì  ì••ì¶•
        speed_factor = min(1.5, 1.0 / compression_ratio)  # ìµœëŒ€ 80% ë¹ ë¥´ê²Œ

        # ê¸´ ë¬¸ì¥ì— ëŒ€í•œ ì¶”ê°€ ì••ì¶•
        if len(text_content) > 50:  # ê¸´ ë¬¸ì¥
            speed_factor = min(speed_factor * 1.1, 2.0)  # ì¶”ê°€ë¡œ 10% ë” ë¹ ë¥´ê²Œ, ìµœëŒ€ 2ë°°ì†

        return adjust_audio_speed(audio_segment, speed_factor)


def remove_excessive_silence(audio_segment, max_silence_ms=500):
    """
    ê³¼ë„í•œ ë¬´ìŒ êµ¬ê°„ ì œê±°
    Args:
        audio_segment: ì²˜ë¦¬í•  ì˜¤ë””ì˜¤
        max_silence_ms: í—ˆìš©í•  ìµœëŒ€ ë¬´ìŒ ê¸¸ì´
    """
    try:
        # ë¬´ìŒ ì„ê³„ê°’ ì„¤ì • (-40dB)
        silence_thresh = audio_segment.dBFS - 40

        # ë¬´ìŒ êµ¬ê°„ íƒì§€
        chunks = []
        current_pos = 0
        chunk_size = 100  # 100ms ë‹¨ìœ„ë¡œ ì²˜ë¦¬

        while current_pos < len(audio_segment):
            chunk = audio_segment[current_pos:current_pos + chunk_size]

            # ë¬´ìŒ ì—¬ë¶€ í™•ì¸
            if chunk.dBFS < silence_thresh:
                # ë¬´ìŒ êµ¬ê°„ - ê¸¸ì´ ì œí•œ
                silence_length = min(chunk_size, max_silence_ms)
                chunks.append(AudioSegment.silent(duration=silence_length))

                # ì—°ì† ë¬´ìŒ ê±´ë„ˆë›°ê¸°
                next_pos = current_pos + chunk_size
                while next_pos < len(audio_segment):
                    next_chunk = audio_segment[next_pos:next_pos + chunk_size]
                    if next_chunk.dBFS >= silence_thresh:
                        break
                    next_pos += chunk_size
                current_pos = next_pos
            else:
                # ìŒì„± êµ¬ê°„ - ê·¸ëŒ€ë¡œ ìœ ì§€
                chunks.append(chunk)
                current_pos += chunk_size

        return sum(chunks) if chunks else audio_segment

    except Exception as e:
        log_message(f"ë¬´ìŒ ì œê±° ì˜¤ë¥˜: {e}")
        return audio_segment


# -------------------------------------
# ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© (ì›ë³¸ íƒ€ì´ë° ë³´ì¡´) - ê°œì„ ëœ ë²„ì „
# -------------------------------------
def merge_segments_preserve_timing(segments, original_duration_ms, segments_dir, output_path,
                                   length_handling="preserve", overlap_handling="fade", max_extension=50,
                                   enable_smart_compression=True):
    """
    ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ì›ë³¸ íƒ€ì„ë¼ì¸ì— ë§ì¶° ë³‘í•© (ìŠ¤ë§ˆíŠ¸ ì••ì¶• ê¸°ëŠ¥ ì¶”ê°€)
    í•©ì„±ëœ ìŒì„±ì´ ë” ê¸¸ ê²½ìš° ì„¤ì •ì— ë”°ë¼ ì²˜ë¦¬
    
    Args:
        length_handling: "preserve" (ì™„ì „ ë³´ì¡´) ë˜ëŠ” "fit" (ì›ë³¸ ê¸¸ì´ ë§ì¶¤)
        overlap_handling: "fade" (í˜ì´ë“œ ì²˜ë¦¬) ë˜ëŠ” "cut" (ìë¥´ê¸°)
        max_extension: ìµœëŒ€ í™•ì¥ í—ˆìš© ë¹„ìœ¨ (%)
        enable_smart_compression: ìŠ¤ë§ˆíŠ¸ ì••ì¶• í™œì„±í™” ì—¬ë¶€
    """
    # ì˜¬ë°”ë¥¸ ë² ì´ìŠ¤ ì´ë¦„ ì¶”ì¶œ
    if 'cosy_output' in segments_dir:
        # segments_dirì´ /path/to/split_audio/base_name/cosy_output/language/type í˜•íƒœì¸ ê²½ìš°
        path_parts = segments_dir.split(os.sep)
        cosy_index = None
        for i, part in enumerate(path_parts):
            if part == 'cosy_output':
                cosy_index = i
                break

        if cosy_index and cosy_index >= 2:
            # split_audio ë‹¤ìŒì— ì˜¤ëŠ” ë¶€ë¶„ì´ ë² ì´ìŠ¤ ì´ë¦„
            split_audio_index = None
            for i, part in enumerate(path_parts):
                if part == 'split_audio':
                    split_audio_index = i
                    break

            if split_audio_index is not None and split_audio_index + 1 < len(path_parts):
                base = path_parts[split_audio_index + 1]
            else:
                # fallback
                base = os.path.basename(os.path.dirname(os.path.dirname(segments_dir)))
        else:
            # fallback
            base = os.path.basename(os.path.dirname(os.path.dirname(segments_dir)))
    else:
        # segments_dirì´ ì§ì ‘ ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆëŠ” í´ë”ì¸ ê²½ìš°
        base = os.path.basename(segments_dir)

    log_message(f"ë³‘í•© ë² ì´ìŠ¤ ì´ë¦„: {base}, ì„¸ê·¸ë¨¼íŠ¸ ë””ë ‰í† ë¦¬: {segments_dir}")
    log_message(f"ğŸ”§ ì²˜ë¦¬ ì„¤ì •: ê¸¸ì´={length_handling}, ê²¹ì¹¨={overlap_handling}, ìµœëŒ€í™•ì¥={max_extension}%")
    log_message(f"ğŸ§  ìŠ¤ë§ˆíŠ¸ ì••ì¶•: {'í™œì„±í™”' if enable_smart_compression else 'ë¹„í™œì„±í™”'}")

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë“¤ í™•ì¸
    if os.path.exists(segments_dir):
        available_files = [f for f in os.listdir(segments_dir) if f.endswith('.wav')]
        log_message(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ë“¤: {available_files}")
    else:
        log_message(f"ê²½ê³ : ì„¸ê·¸ë¨¼íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {segments_dir}")
        return

    # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìš°ì„ ìˆœìœ„ ê³„ì‚°ìš©)
    base_dir = os.path.dirname(segments_dir) if 'cosy_output' in segments_dir else segments_dir
    ko_text_dir = os.path.join(base_dir, 'txt', 'ko')

    # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ í•©ì„± ê¸¸ì´ë¥¼ ë¨¼ì € í™•ì¸í•˜ì—¬ ì „ì²´ ê¸¸ì´ ê³„ì‚°
    segment_info = []
    total_extension = 0
    max_allowed_extension = original_duration_ms * max_extension / 100  # ìµœëŒ€ í—ˆìš© í™•ì¥ëŸ‰

    for idx, (start_ms, end_ms) in enumerate(segments, start=1):
        original_duration = end_ms - start_ms
        seg_path = os.path.join(segments_dir, f"{base}_{idx:03d}.wav")

        # í…ìŠ¤íŠ¸ ë‚´ìš© ë¡œë“œ (ìš°ì„ ìˆœìœ„ ê³„ì‚°ìš©)
        text_content = ""
        if enable_smart_compression:
            text_file = os.path.join(ko_text_dir, f"{base}_{idx:03d}.ko.txt")
            if os.path.exists(text_file):
                try:
                    with open(text_file, 'r', encoding='utf-8') as f:
                        text_content = f.read().strip()
                except Exception:
                    text_content = ""

        if os.path.exists(seg_path):
            synth_segment = AudioSegment.from_file(seg_path)
            synth_duration = len(synth_segment)

            # ìŠ¤ë§ˆíŠ¸ ì••ì¶• ì ìš©
            if enable_smart_compression and synth_duration > original_duration:
                log_message(f"ğŸ§  ì„¸ê·¸ë¨¼íŠ¸ {idx}: ìŠ¤ë§ˆíŠ¸ ì••ì¶• ì ìš© ì¤‘... (ì›ë³¸: {original_duration}ms â†’ í•©ì„±: {synth_duration}ms)")

                # ìš°ì„ ìˆœìœ„ ê³„ì‚°
                priority = calculate_segment_priority(text_content, synth_duration)
                log_message(
                    f"   ìš°ì„ ìˆœìœ„: {priority:.2f} ({'ë†’ìŒ' if priority >= 0.8 else 'ì¤‘ê°„' if priority >= 0.5 else 'ë‚®ìŒ'})")

                # ê³¼ë„í•œ ë¬´ìŒ ì œê±°
                synth_segment = remove_excessive_silence(synth_segment, max_silence_ms=300)
                silence_removed_duration = len(synth_segment)
                if silence_removed_duration < synth_duration:
                    log_message(f"   ë¬´ìŒ ì œê±°: {synth_duration}ms â†’ {silence_removed_duration}ms")
                    synth_duration = silence_removed_duration

                # ì—¬ì „íˆ ê¸¸ë©´ ìŠ¤ë§ˆíŠ¸ ì••ì¶• ì ìš©
                if synth_duration > original_duration:
                    if length_handling == "fit":
                        # ì›ë³¸ ê¸¸ì´ì— ë§ì¶¤ ëª¨ë“œ
                        synth_segment = smart_audio_compression(synth_segment, original_duration, text_content)
                        synth_duration = len(synth_segment)
                        log_message(f"   ì••ì¶• ì™„ë£Œ: {synth_duration}ms (ëª©í‘œ: {original_duration}ms)")
                    else:
                        # ë³´ì¡´ ëª¨ë“œì—ì„œë„ ê·¹ë‹¨ì ì¸ ê²½ìš° ì œí•œì  ì••ì¶•
                        max_allowed_length = int(original_duration * 1.5)  # ìµœëŒ€ 50% í™•ì¥
                        if synth_duration > max_allowed_length:
                            synth_segment = smart_audio_compression(synth_segment, max_allowed_length, text_content)
                            synth_duration = len(synth_segment)
                            log_message(f"   ì œí•œì  ì••ì¶•: {synth_duration}ms (ìµœëŒ€í—ˆìš©: {max_allowed_length}ms)")

            # ê¸°ì¡´ ê¸¸ì´ ì²˜ë¦¬ ë°©ì‹
            elif length_handling == "fit" and not enable_smart_compression:
                # ì›ë³¸ ê¸¸ì´ì— ë§ì¶¤ (ìµœëŒ€ 20% í™•ì¥ê¹Œì§€ë§Œ í—ˆìš©)
                max_segment_length = int(original_duration * 1.2)
                if synth_duration > max_segment_length:
                    # ìì—°ìŠ¤ëŸ¬ìš´ í˜ì´ë“œì•„ì›ƒìœ¼ë¡œ ì¡°ì •
                    synth_segment = synth_segment[:max_segment_length].fade_out(100)
                    synth_duration = len(synth_segment)
                    log_message(f"ğŸ”§ ì„¸ê·¸ë¨¼íŠ¸ {idx}: ê¸¸ì´ ì¡°ì • {len(synth_segment)}ms â†’ {synth_duration}ms")
                elif synth_duration < original_duration:
                    # ì§§ì€ ê²½ìš° ë¬´ìŒ íŒ¨ë”©
                    padding = AudioSegment.silent(duration=original_duration - synth_duration)
                    synth_segment = synth_segment + padding
                    synth_duration = len(synth_segment)

            extension = max(0, synth_duration - original_duration)

            # ìµœëŒ€ í™•ì¥ ì œí•œ ì ìš© (ê¸°ì¡´ ë¡œì§)
            if extension > max_allowed_extension / len(segments):  # ì„¸ê·¸ë¨¼íŠ¸ë‹¹ í‰ê·  í—ˆìš©ëŸ‰
                allowed_length = original_duration + int(max_allowed_extension / len(segments))
                synth_segment = synth_segment[:allowed_length].fade_out(200)
                synth_duration = len(synth_segment)
                extension = synth_duration - original_duration
                log_message(f"ğŸ”§ ì„¸ê·¸ë¨¼íŠ¸ {idx}: ìµœëŒ€ í™•ì¥ ì œí•œ ì ìš© â†’ {synth_duration}ms")

            total_extension += extension

            segment_info.append({
                'idx': idx,
                'start_ms': start_ms,
                'end_ms': end_ms,
                'original_duration': original_duration,
                'synth_duration': synth_duration,
                'extension': extension,
                'segment': synth_segment,
                'exists': True,
                'text_content': text_content
            })

            log_message(f"ì„¸ê·¸ë¨¼íŠ¸ {idx}: ì›ë³¸ {original_duration}ms â†’ í•©ì„± {synth_duration}ms (í™•ì¥: {extension}ms)")
        else:
            segment_info.append({
                'idx': idx,
                'start_ms': start_ms,
                'end_ms': end_ms,
                'original_duration': original_duration,
                'synth_duration': 0,
                'extension': 0,
                'segment': None,
                'exists': False
            })
            log_message(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ {idx}: íŒŒì¼ ì—†ìŒ")

    # ìµœì¢… ê¸¸ì´ ê³„ì‚°
    if length_handling == "preserve":
        final_duration_ms = original_duration_ms + total_extension
        log_message(f"ğŸ“ ì˜ˆìƒ ìµœì¢… ê¸¸ì´: {original_duration_ms}ms + {total_extension}ms = {final_duration_ms}ms")
    else:
        final_duration_ms = original_duration_ms + min(total_extension, int(max_allowed_extension))
        log_message(f"ğŸ“ ì¡°ì •ëœ ìµœì¢… ê¸¸ì´: {final_duration_ms}ms (ì›ë³¸: {original_duration_ms}ms)")

    # ìµœì¢… ê¸¸ì´ë§Œí¼ì˜ ë¬´ìŒìœ¼ë¡œ ì‹œì‘
    merged = AudioSegment.silent(duration=final_duration_ms)

    # ëˆ„ì  ì‹œê°„ ì˜¤í”„ì…‹ (ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì˜ í™•ì¥ìœ¼ë¡œ ì¸í•œ ì§€ì—°)
    time_offset = 0

    for seg_info in segment_info:
        if seg_info['exists']:
            # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ ë°°ì¹˜ ìœ„ì¹˜ (ì‹œê°„ ì˜¤í”„ì…‹ ì ìš©)
            adjusted_start = seg_info['start_ms'] + time_offset
            adjusted_end = adjusted_start + seg_info['synth_duration']

            # í•©ì„±ëœ ì„¸ê·¸ë¨¼íŠ¸ ë°°ì¹˜
            synth_segment = seg_info['segment']

            # ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ì™€ì˜ ì¶©ëŒ ê²€ì‚¬
            next_segment_start = None
            for next_seg in segment_info:
                if next_seg['idx'] > seg_info['idx'] and next_seg['exists']:
                    next_segment_start = next_seg['start_ms'] + time_offset + seg_info['extension']
                    break

            # ì¶©ëŒì´ ìˆëŠ” ê²½ìš° ê²¹ì¹˜ëŠ” ë¶€ë¶„ ì²˜ë¦¬
            if next_segment_start and adjusted_end > next_segment_start:
                overlap_duration = adjusted_end - next_segment_start
                log_message(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ {seg_info['idx']}: ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ì™€ {overlap_duration}ms ê²¹ì¹¨ ê°ì§€")

                if overlap_handling == "fade":
                    # ê²¹ì¹˜ëŠ” ë¶€ë¶„ì„ í˜ì´ë“œì•„ì›ƒ/í˜ì´ë“œì¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬
                    if overlap_duration < len(synth_segment):
                        fade_duration = min(overlap_duration // 2, 500)  # ìµœëŒ€ 0.5ì´ˆ í˜ì´ë“œ
                        synth_segment = synth_segment.fade_out(fade_duration)
                        log_message(f"ğŸ”§ ì„¸ê·¸ë¨¼íŠ¸ {seg_info['idx']}: {fade_duration}ms í˜ì´ë“œì•„ì›ƒ ì ìš©")
                elif overlap_handling == "cut":
                    # ê²¹ì¹˜ëŠ” ë¶€ë¶„ ìë¥´ê¸°
                    synth_segment = synth_segment[:len(synth_segment) - overlap_duration]
                    log_message(f"âœ‚ï¸ ì„¸ê·¸ë¨¼íŠ¸ {seg_info['idx']}: {overlap_duration}ms ì˜ë¼ë‚´ê¸° ì ìš©")

            # ì„¸ê·¸ë¨¼íŠ¸ ë°°ì¹˜ (ì˜¤ë²„ë ˆì´ ë°©ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ)
            merged = merged.overlay(synth_segment, position=adjusted_start)

            # ì‹œê°„ ì˜¤í”„ì…‹ ì—…ë°ì´íŠ¸
            if length_handling == "preserve":
                time_offset += seg_info['extension']

            log_message(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ {seg_info['idx']}: {adjusted_start}ms~{adjusted_end}ms ë°°ì¹˜ ì™„ë£Œ")
        else:
            log_message(f"â­ï¸ ì„¸ê·¸ë¨¼íŠ¸ {seg_info['idx']}: ê±´ë„ˆë›°ê¸° (íŒŒì¼ ì—†ìŒ)")

    # ìµœì¢… ê¸¸ì´ ê²€ì¦
    actual_length = len(merged)
    log_message(f"ğŸ“Š ì‹¤ì œ ìµœì¢… ê¸¸ì´: {actual_length}ms")

    # ê²°ê³¼ ì €ì¥
    merged.export(output_path, format="wav")
    log_message(f"ğŸµ ìŠ¤ë§ˆíŠ¸ íƒ€ì„ë¼ì¸ ë³‘í•© ì™„ë£Œ: {output_path}")
    log_message(
        f"ğŸ“ˆ ê¸¸ì´ ë³€í™”: {original_duration_ms}ms â†’ {actual_length}ms (ë³€í™”: {actual_length - original_duration_ms:+d}ms)")

    # í’ˆì§ˆ ë³´ì¥ ë©”ì‹œì§€
    if length_handling == "preserve":
        if actual_length >= original_duration_ms:
            log_message("âœ… í•©ì„± ìŒì„± ì™„ì „ ë³´ì¡´! ëª¨ë“  ë‚´ìš©ì´ ì˜ë¦¬ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            log_message("âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ê¸¸ì´ ë‹¨ì¶• ë°œìƒ")
    else:
        log_message(f"âœ… ì›ë³¸ ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì • ì™„ë£Œ (ìµœëŒ€ {max_extension}% í™•ì¥)")

    if enable_smart_compression:
        log_message("ğŸ§  ìŠ¤ë§ˆíŠ¸ ì••ì¶• ê¸°ëŠ¥ìœ¼ë¡œ ë”ìš± ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.")

    return actual_length

# -------------------------------------
# Whisper ì²˜ë¦¬ í•¨ìˆ˜
# -------------------------------------

# -------------------------------------
# Ko â†’ EN ë²ˆì—­ í•¨ìˆ˜ (Gemma3 ê¸°ë°˜)
# -------------------------------------
def translate_ko_to_en(ko_folder: str, en_folder: str):
    """
    ko_folder ë‚´ì˜ ê° .ko.txt íŒŒì¼ì„ Gemma3ë¡œ ë²ˆì—­ ë° ì˜ì—­í•˜ì—¬
    en_folderì— ê°™ì€ ì´ë¦„ìœ¼ë¡œ .en.txtë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    for fname in os.listdir(ko_folder):
        if fname.endswith('.ko.txt'):
            ko_path = os.path.join(ko_folder, fname)
            en_path = os.path.join(en_folder, fname.replace('.ko.txt', '.en.txt'))
            try:
                with open(ko_path, 'r', encoding='utf-8') as f:
                    text = f.read().strip()
                # ì‹¤ì œ ë²ˆì—­ ë¶€ë¶„ì€ Gemma3 ë“± ì™¸ë¶€ API/ëª¨ë“ˆë¡œ ëŒ€ì²´
                translated = f"[EN] {text}"
                with open(en_path, 'w', encoding='utf-8') as f:
                    f.write(translated)
                log_message(f"ë²ˆì—­ ì™„ë£Œ: {fname} â†’ {os.path.basename(en_path)}")
            except Exception as e:
                log_message(f"ë²ˆì—­ ì˜¤ë¥˜: {fname} ({e})")
    log_message(f"âœ… {ko_folder} ë‚´ Ko â†’ EN ë²ˆì—­ ë° ì˜ì—­ ì™„ë£Œ")

# -------------------------------------
# ì „ì²´ Ko í…ìŠ¤íŠ¸ í´ë” ì¼ê´„ ë²ˆì—­ í•¨ìˆ˜
# -------------------------------------
def batch_translate_all():
    """
    split_audio í•˜ìœ„ ëª¨ë“  base ë””ë ‰í† ë¦¬ì˜ txt/ko í´ë”ë¥¼ ìˆœíšŒí•˜ë©°
    Gemma3ë¡œ ë²ˆì—­ ë° ì˜ì—­ í›„ txt/en í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    root_dir = os.path.join(os.getcwd(), 'split_audio')
    if not os.path.isdir(root_dir):
        log_message(f"ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤: {root_dir}")
        return

    for base in os.listdir(root_dir):
        ko_folder = os.path.join(root_dir, base, 'txt', 'ko')
        en_folder = os.path.join(root_dir, base, 'txt', 'en')
        if os.path.isdir(ko_folder):
            os.makedirs(en_folder, exist_ok=True)
            translate_ko_to_en(ko_folder, en_folder)
    log_message('âœ… ì „ì²´ Ko â†’ EN ë²ˆì—­ ë° ì˜ì—­ ì™„ë£Œ')

def run_whisper_directory(output_dir: str):
    wav_folder = os.path.join(output_dir, 'wav')
    base = os.path.basename(output_dir)
    wav_files = sorted([
        os.path.join(wav_folder, f) for f in os.listdir(wav_folder)
        if f.startswith(f"{base}_") and f.endswith('.wav')
    ])
    if not wav_files:
        log_message("ë¶„í• ëœ wav íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    txt_root = os.path.join(output_dir, 'txt')
    ko_folder = os.path.join(txt_root, 'ko')
    en_folder = os.path.join(txt_root, 'en')
    os.makedirs(ko_folder, exist_ok=True)
    os.makedirs(en_folder, exist_ok=True)

    model_path, is_coreml = get_model_path()
    log_message(f'Whisper ëª¨ë¸: {model_path} (CoreML: {is_coreml})')

    # í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬, EN í´ë”ëŠ” ë¹ˆ ì±„ ìœ ì§€
    cmd = [WHISPER_CLI, '--no-prints', '-m', model_path, '-otxt', '-l', 'ko'] + wav_files

    # CoreMLì€ ìë™ìœ¼ë¡œ ì‚¬ìš©ë¨ (ë³„ë„ ì˜µì…˜ ë¶ˆí•„ìš”)
    if is_coreml and IS_MACOS:
        log_message('CoreML ëª¨ë¸ ì‚¬ìš© ì¤‘ (ìë™ ê°€ì†)')

    # í†µí•© ë¡œê¹… ì‹œìŠ¤í…œìœ¼ë¡œ ì‹¤í–‰
    return_code = run_command_with_logging(cmd, cwd=wav_folder, description="Whisper í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬")
    log_message(f"whisper KO ì²˜ë¦¬ ì™„ë£Œ (return code: {return_code})")

    for wav in wav_files:
        name = os.path.splitext(os.path.basename(wav))[0]
        src = os.path.join(wav_folder, f"{name}.wav.txt")
        dst = os.path.join(ko_folder, f"{name}.ko.txt")
        if os.path.exists(src):
            # ì½ê³ , ë¹ˆ ì¤„ ì œê±° í›„ í•œ ì¤„ë¡œ í•©ì¹˜ê¸°
            with open(src, 'r', encoding='utf-8') as rf:
                lines = [line.strip() for line in rf if line.strip()]
            single_line = ' '.join(lines)
            # ko í´ë”ì— ì €ì¥
            with open(dst, 'w', encoding='utf-8') as wf:
                wf.write(single_line)
            log_message(f"í•œêµ­ì–´ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸° ë° ì €ì¥: {os.path.basename(dst)}")
        else:
            log_message(f"ì—ëŸ¬: í•„ì‚¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(src)}")

    log_message("í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ ìƒì„± ì™„ë£Œ. EN í´ë”ëŠ” ë¹„ì›Œë‘ì—ˆìŠµë‹ˆë‹¤.")
    log_message("í•œêµ­ì–´ í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ. ë‹¤êµ­ì–´ ë²ˆì—­ ì‹œì‘...")

    # ë‹¤êµ­ì–´ ë²ˆì—­ ì²˜ë¦¬
    translation_length = float(translation_length_var.get()) if 'translation_length_var' in globals() else 0.8
    quality_mode = translation_quality_var.get() if 'translation_quality_var' in globals() else "balanced"

    # ì„ íƒëœ ì–¸ì–´ë“¤ í™•ì¸
    selected_languages = []
    if enable_english_var.get():
        selected_languages.append("english")
    if enable_chinese_var.get():
        selected_languages.append("chinese")
    if enable_japanese_var.get():
        selected_languages.append("japanese")

    if not selected_languages:
        selected_languages = ["english"]  # ê¸°ë³¸ê°’

    log_message(f"ë²ˆì—­ ëŒ€ìƒ ì–¸ì–´: {', '.join(selected_languages)}")
    log_message(f"ë²ˆì—­ ì„¤ì • - ê¸¸ì´ ë¹„ìœ¨: {translation_length}, í’ˆì§ˆ ëª¨ë“œ: {quality_mode}")

    # ë‹¤êµ­ì–´ ë²ˆì—­ ì‹¤í–‰
    try:
        batch_translate(
            input_dir=ko_folder,
            output_dir=txt_root,
            length_ratio=translation_length,
            target_languages=selected_languages
        )
        log_message("âœ… ë‹¤êµ­ì–´ ë²ˆì—­ ì™„ë£Œ")

        # ë©”ëª¨ë¦¬ í•´ì œ í™•ì¸ ë¡œê·¸ ì¶”ê°€
        log_message("ğŸ§¹ Gemma3 ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ - CosyVoice í•©ì„± ì¤€ë¹„")
    except Exception as e:
        log_message(f"âŒ ë²ˆì—­ ì˜¤ë¥˜: {e}")
        return

    # ìŒì„± í•©ì„± ì²˜ë¦¬ - ê° ì–¸ì–´ë³„ë¡œ ì˜ì—­ë§Œ ì²˜ë¦¬
    for synthesis_lang in selected_languages:
        lang_name = SUPPORTED_LANGUAGES[synthesis_lang]['name'].lower()

        # ì˜ì—­(free)ë§Œ ì²˜ë¦¬
        translation_type = "free"
        text_dir = os.path.join(txt_root, lang_name, translation_type)

        if not os.path.exists(text_dir):
            log_message(f"â­ï¸ {SUPPORTED_LANGUAGES[synthesis_lang]['name']} {translation_type} í…ìŠ¤íŠ¸ ì—†ìŒ, ê±´ë„ˆë›°ê¸°")
            continue

        log_message(f"ğŸ”Š {SUPPORTED_LANGUAGES[synthesis_lang]['name']} ({translation_type}) ìŒì„± í•©ì„± ì‹œì‘...")

        # CosyVoice2 í•©ì„± í˜¸ì¶œ
        cosy_out = os.path.join(output_dir, 'cosy_output', lang_name, translation_type)
        os.makedirs(cosy_out, exist_ok=True)

        # ë©”ëª¨ë¦¬ ì •ë¦¬ (í•©ì„± ì „)
        import gc
        gc.collect()

        try:
            # UIì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
            enable_instruct = enable_instruct_var.get()
            command_mode = command_mode_var.get()
            manual_command = None
            if command_mode == 'manual':
                manual_command = manual_command_var.get()

            log_message(f"  ì–¸ì–´: {SUPPORTED_LANGUAGES[synthesis_lang]['name']}")
            log_message(f"  ë²ˆì—­ ìœ í˜•: {translation_type}")
            log_message(f"  Instruct2 í™œì„±í™”: {enable_instruct}")
            if manual_command:
                log_message(f"  ìˆ˜ë™ ëª…ë ¹ì–´: {manual_command}")

            # CosyVoice2 batch synthesis
            cosy_batch(
                audio_dir=wav_folder,
                prompt_text_dir=ko_folder,
                text_dir=text_dir,  # ì–¸ì–´ë³„ ë²ˆì—­ í…ìŠ¤íŠ¸ ì‚¬ìš©
                out_dir=cosy_out,
                enable_instruct=enable_instruct,
                manual_command=manual_command
            )

            log_message(f"âœ… {SUPPORTED_LANGUAGES[synthesis_lang]['name']} ({translation_type}) í•©ì„± ì™„ë£Œ")

        except Exception as e:
            log_message(f"âŒ {SUPPORTED_LANGUAGES[synthesis_lang]['name']} ({translation_type}) í•©ì„± ì¤‘ ì˜¤ë¥˜: {e}")
            continue

        # í•©ì„± ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
        import gc
        gc.collect()

    # ëª¨ë“  ì–¸ì–´ë³„ë¡œ í•©ì„± ê²°ê³¼ ë³‘í•©
    input_ext = os.path.splitext(input_file_var.get())[1]
    srt_path = os.path.join(output_dir, f"{base}{input_ext}.srt")
    segments = parse_srt_segments(srt_path)
    orig_audio = AudioSegment.from_file(input_file_var.get())
    original_duration_ms = len(orig_audio)
    enable_smart_compression = enable_smart_compression_var.get() if 'enable_smart_compression_var' in globals() else True

    # ê° ì–¸ì–´ë³„ë¡œ ë³‘í•© ìˆ˜í–‰
    for lang in selected_languages:
        lang_name = SUPPORTED_LANGUAGES[lang]['name'].lower()
        # ë‹¨ìˆœí™”ëœ ë³‘í•© ì²˜ë¦¬ - ì˜ì—­(free)ë§Œ ì²˜ë¦¬
        trans_type = "free"
        cosy_out = os.path.join(output_dir, 'cosy_output', lang_name, trans_type)
        if os.path.exists(cosy_out):
            merged_path = os.path.join(output_dir, f"{base}_{lang_name}_merged.wav")
            merge_segments_preserve_timing(
                segments,
                original_duration_ms,
                cosy_out,
                merged_path,
                length_handling=length_handling_var.get(),
                overlap_handling=overlap_handling_var.get(),
                max_extension=int(max_extension_var.get()),
                enable_smart_compression=enable_smart_compression
            )
            log_message(f"ğŸµ {lang_name} ë³‘í•© ì™„ë£Œ: {os.path.basename(merged_path)}")

    log_message(f"ğŸ“ ì–¸ì–´ë³„ í´ë” êµ¬ì¡°:")
    log_message(f"   â””â”€â”€ txt/")
    for lang in selected_languages:
        lang_name_display = SUPPORTED_LANGUAGES[lang]['name'].lower()
        log_message(f"       â”œâ”€â”€ {lang_name_display}/")
        log_message(f"       â”‚   â”œâ”€â”€ literal/ (ì§ì—­)")
        log_message(f"       â”‚   â””â”€â”€ free/ (ì˜ì—­)")
    log_message(f"   â””â”€â”€ cosy_output/")
    for lang in selected_languages:
        lang_name_display = SUPPORTED_LANGUAGES[lang]['name'].lower()
        log_message(f"       â”œâ”€â”€ {lang_name_display}/")
        log_message(f"       â”‚   â”œâ”€â”€ literal/ (ì§ì—­ í•©ì„±)")
        log_message(f"       â”‚   â””â”€â”€ free/ (ì˜ì—­ í•©ì„±)")

# -------------------------------------
# ë©”ì¸ ì²˜ë¦¬ (ë²„íŠ¼ í´ë¦­)
# -------------------------------------

def start_processing():
    # í”Œë«í¼ë³„ íŒŒì¼íƒ€ì… í˜•ì‹ ë¶„ê¸°ì²˜ë¦¬
    if IS_WINDOWS:
        # Windows í˜•ì‹: ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ í™•ì¥ì êµ¬ë¶„
        filetypes = [
            ('All Media Files', '*.wav;*.mp3;*.mp4;*.avi;*.mkv;*.mov;*.wmv;*.flv'),
            ('Audio Files', '*.wav;*.mp3'),
            ('Video Files', '*.mp4;*.avi;*.mkv;*.mov;*.wmv;*.flv'),
            ('WAV files', '*.wav'),
            ('MP3 files', '*.mp3'),
            ('MP4 files', '*.mp4'),
            ('All files', '*.*')
        ]
    else:
        # macOS/Linux í˜•ì‹: ê³µë°±ìœ¼ë¡œ í™•ì¥ì êµ¬ë¶„
        filetypes = [
            ('All Media Files', '*.wav *.mp3 *.mp4 *.avi *.mkv *.mov *.wmv *.flv'),
            ('Audio Files', '*.wav *.mp3'),
            ('Video Files', '*.mp4 *.avi *.mkv *.mov *.wmv *.flv'),
            ('WAV files', '*.wav'),
            ('MP3 files', '*.mp3'),
            ('MP4 files', '*.mp4'),
            ('All files', '*.*')
        ]

    input_file = filedialog.askopenfilename(filetypes=filetypes)
    if not input_file:
        return
    input_file_var.set(input_file)
    base = os.path.splitext(os.path.basename(input_file))[0]
    out  = os.path.join(os.getcwd(), 'split_audio', base)
    os.makedirs(out, exist_ok=True)

    load_config()

    # Remove references to deleted log boxes since logging is now unified
    # install_log_box.configure(state='normal'); install_log_box.delete('1.0', tk.END); install_log_box.configure(state='disabled')
    # audio_log_box.configure(state='normal');   audio_log_box.delete('1.0', tk.END);   audio_log_box.configure(state='disabled')

    def worker():
        try:
            log_message('== whisper.cpp ì‹¤í–‰ (VAD+SRT) ==')
            model_path, is_coreml = get_model_path()
            log_message(f'ì‚¬ìš© ëª¨ë¸: {model_path} (CoreML: {is_coreml})')

            whisper_cmd = [
                WHISPER_CLI,
                '--vad',
                # 1) split-on-word ì œê±°
                # 2) VAD ì˜µì…˜ì„ -f ì´ì „ìœ¼ë¡œ ëª¨ìŒ
                '--vad-model', resource_path('whisper.cpp/models/ggml-silero-v5.1.2.bin'),  # ë˜ëŠ” '-vm'
                '--vad-threshold',           str(vad_config['threshold']),
                '--vad-min-speech-duration-ms', str(vad_config['min_speech_duration_ms']),  # í•„í„°ë§ ê¸°ì¤€
                '--vad-min-silence-duration-ms', str(vad_config['min_silence_duration_ms']),
                '--vad-max-speech-duration-s', str(vad_config['max_speech_duration_s']),
                '--vad-speech-pad-ms',       str(vad_config['speech_pad_ms']),
                '-f', input_file,                                                     # ì…ë ¥ íŒŒì¼
                '-m', model_path,
                '--output-srt',
                '--language', 'ko',
            ]

            # CoreMLì€ ìë™ìœ¼ë¡œ ì‚¬ìš©ë¨ (ë³„ë„ ì˜µì…˜ ë¶ˆí•„ìš”)
            # if is_coreml and IS_MACOS:
            #     whisper_cmd.extend(['--use-coreml'])
            #     install_log_queue.put('CoreML ê°€ì† í™œì„±í™”')

            # whisper-cli ëŠ” WHISPER_CLI ë””ë ‰í„°ë¦¬ì—ì„œ ì‹¤í–‰í•´ì•¼ .srt ê°€ out ì— ìƒì„±ë©ë‹ˆë‹¤
            run_command_with_logging(whisper_cmd, cwd=os.path.dirname(input_file), description="whisper.cpp VAD+SRT ì²˜ë¦¬")
            log_message('== SRT ìƒì„± ì™„ë£Œ ==')
            # ensure .srt from input directory is moved into out if not present
            srt_files = [f for f in os.listdir(out) if f.lower().endswith('.srt')]
            if not srt_files:
                input_dir = os.path.dirname(input_file)
                moved = False
                for f in os.listdir(input_dir):
                    if f.startswith(base) and f.lower().endswith('.srt'):
                        shutil.move(os.path.join(input_dir, f), out)
                        log_message(f'Moved SRT from input dir: {f}')
                        moved = True
                        break
                if not moved:
                    log_message('DEBUG: No .srt found in input directory')
            log_message(f"OUT DIR after move: {os.listdir(out)}")

            srt_files = [f for f in os.listdir(out) if f.lower().endswith('.srt')]
            if not srt_files:
                log_message('ì—ëŸ¬: SRT íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                return
            srt_path = os.path.join(out, srt_files[0])
            log_message(f'== SRT íŒŒì¼ ë°œê²¬: {srt_files[0]} ==')

            segments, orig_dur = split_audio_by_srt(input_file, srt_path, out)
            log_message(f'== {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì™„ë£Œ ==')

            run_whisper_directory(out)
            log_message('== Whisper ì²˜ë¦¬ ì™„ë£Œ ==')

        except Exception as e:
            log_message(f'ì—ëŸ¬ ë°œìƒ: {e}')

    threading.Thread(target=worker, daemon=True).start()

# -------------------------------------
# GUI êµ¬ì„±
# -------------------------------------
def save_config():
    try:
        vad_config['threshold'] = float(threshold_entry.get())
        vad_config['min_speech_duration_ms'] = int(min_speech_entry.get())
        vad_config['max_speech_duration_s'] = float(max_speech_entry.get())
        vad_config['min_silence_duration_ms'] = int(min_silence_entry.get())
        vad_config['speech_pad_ms'] = int(pad_entry.get())
        with open(resource_path(CONFIG_FILE), 'w', encoding='utf-8') as f:
            json.dump(vad_config, f, indent=4, ensure_ascii=False)
        log_message('ì„¤ì • ì €ì¥ ì™„ë£Œ')
    except Exception as e:
        log_message(f'ì„¤ì • ì €ì¥ ì˜¤ë¥˜: {e}')


def load_config():
    global vad_config
    path = resource_path(CONFIG_FILE)
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            loaded = json.load(f)
    else:
        loaded = {}
    vad_config = DEFAULT_CONFIG.copy()
    vad_config.update(loaded)
    log_message(f'í˜„ì¬ VAD ì„¤ì •: {vad_config}')

root = tk.Tk()
input_file_var = tk.StringVar()
root.title('STT Voice Splitter')
root.geometry('1400x900')  # í™”ë©´ í¬ê¸° í™•ëŒ€

nb = ttk.Notebook(root)
main_tab     = ttk.Frame(nb)
settings_tab = ttk.Frame(nb)
log_tab = ttk.Frame(nb)  # ë¡œê·¸ íƒ­ ì¶”ê°€
nb.add(main_tab, text='ë©”ì¸')
nb.add(settings_tab, text='ì„¤ì •')
nb.add(log_tab, text='ë¡œê·¸')
nb.pack(expand=1, fill='both')

ttk.Button(main_tab, text='ì‹œì‘', command=start_processing).pack(pady=5)

# SRTë§Œ ìƒì„±í•˜ëŠ” ë²„íŠ¼ ì¶”ê°€
ttk.Button(main_tab, text='SRT ì „ìš© ìƒì„±', command=generate_srt_only).pack(pady=5)

# í•©ì„± íƒ€ì… ì„ íƒ ì¶”ê°€
synthesis_frame = ttk.Frame(main_tab)
synthesis_frame.pack(pady=5)

# Instruct2 í™œì„±í™” ì²´í¬ë°•ìŠ¤
enable_instruct_var = tk.BooleanVar(value=False)
instruct_checkbox = ttk.Checkbutton(synthesis_frame, text='Instruct2 í•©ì„± í™œì„±í™”',
                                    variable=enable_instruct_var)
instruct_checkbox.pack(side=tk.LEFT, padx=(0, 20))

# ë³‘í•©í•  í•©ì„± ê²°ê³¼ ì„ íƒ
ttk.Label(synthesis_frame, text='ë³‘í•©í•  í•©ì„± ê²°ê³¼:').pack(side=tk.LEFT, padx=(0, 10))
synthesis_type_var = tk.StringVar(value="Zero-shot")
ttk.Radiobutton(synthesis_frame, text='Zero-shot', variable=synthesis_type_var, value='Zero-shot').pack(side=tk.LEFT,
                                                                                                        padx=5)
ttk.Radiobutton(synthesis_frame, text='Instruct2', variable=synthesis_type_var, value='Instruct2').pack(side=tk.LEFT,
                                                                                                        padx=5)

# Instruct2 ì„¤ì • í”„ë ˆì„
instruct_frame = ttk.LabelFrame(main_tab, text="Instruct2 ì„¤ì •")
instruct_frame.pack(pady=5, padx=10, fill='x')

# ëª…ë ¹ì–´ ì…ë ¥ ë°©ì‹ ì„ íƒ
command_mode_var = tk.StringVar(value="auto")
ttk.Label(instruct_frame, text="ëª…ë ¹ì–´ ì„¤ì •:").grid(row=0, column=0, sticky='w', padx=5, pady=2)
ttk.Radiobutton(instruct_frame, text='ìë™ ë¶„ì„', variable=command_mode_var, value='auto').grid(row=0, column=1, sticky='w',
                                                                                            padx=5)
ttk.Radiobutton(instruct_frame, text='ìˆ˜ë™ ì…ë ¥', variable=command_mode_var, value='manual').grid(row=0, column=2,
                                                                                              sticky='w', padx=5)

# ìˆ˜ë™ ëª…ë ¹ì–´ ì…ë ¥
manual_command_var = tk.StringVar(value="ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´")
ttk.Label(instruct_frame, text="ëª…ë ¹ì–´:").grid(row=1, column=0, sticky='w', padx=5, pady=2)
manual_command_entry = ttk.Entry(instruct_frame, textvariable=manual_command_var, width=40)
manual_command_entry.grid(row=1, column=1, columnspan=2, sticky='w', padx=5, pady=2)

# ì‚¬ì „ ì •ì˜ëœ ëª…ë ¹ì–´ ë²„íŠ¼ë“¤
preset_frame = ttk.Frame(instruct_frame)
preset_frame.grid(row=2, column=0, columnspan=3, sticky='w', padx=5, pady=5)

preset_commands = [
    "ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´", "í™œê¸°ì°¨ê²Œ ë§í•´", "ì°¨ë¶„í•˜ê²Œ ë§í•´",
    "ê°ì •ì ìœ¼ë¡œ ë§í•´", "ì²œì²œíˆ ë§í•´", "ë¹ ë¥´ê²Œ ë§í•´"
]


def set_preset_command(cmd):
    manual_command_var.set(cmd)


for i, cmd in enumerate(preset_commands):
    btn = ttk.Button(preset_frame, text=cmd,
                     command=lambda c=cmd: set_preset_command(c))
    btn.grid(row=i // 3, column=i % 3, padx=2, pady=2, sticky='w')

# íƒ€ì„ë¼ì¸ ë° ê¸¸ì´ ì²˜ë¦¬ ì„¤ì • í”„ë ˆì„
timeline_frame = ttk.LabelFrame(main_tab, text="íƒ€ì„ë¼ì¸ & ê¸¸ì´ ì²˜ë¦¬")
timeline_frame.pack(pady=5, padx=10, fill='x')

# ê¸¸ì´ ì²˜ë¦¬ ë°©ì‹ ì„ íƒ
length_handling_var = tk.StringVar(value="preserve")
ttk.Label(timeline_frame, text="í•©ì„± ìŒì„± ê¸¸ì´ ì²˜ë¦¬:").grid(row=0, column=0, sticky='w', padx=5, pady=2)
ttk.Radiobutton(timeline_frame, text='ì™„ì „ ë³´ì¡´ (ì¶”ì²œ)', variable=length_handling_var, value='preserve').grid(row=0, column=1,
                                                                                                        sticky='w',
                                                                                                        padx=5)
ttk.Radiobutton(timeline_frame, text='ì›ë³¸ ê¸¸ì´ ë§ì¶¤', variable=length_handling_var, value='fit').grid(row=0, column=2,
                                                                                                 sticky='w', padx=5)

# ê²¹ì¹¨ ì²˜ë¦¬ ë°©ì‹
overlap_handling_var = tk.StringVar(value="fade")
ttk.Label(timeline_frame, text="ì„¸ê·¸ë¨¼íŠ¸ ê²¹ì¹¨ ì²˜ë¦¬:").grid(row=1, column=0, sticky='w', padx=5, pady=2)
ttk.Radiobutton(timeline_frame, text='í˜ì´ë“œ ì²˜ë¦¬ (ì¶”ì²œ)', variable=overlap_handling_var, value='fade').grid(row=1, column=1,
                                                                                                      sticky='w',
                                                                                                      padx=5)
ttk.Radiobutton(timeline_frame, text='ìë¥´ê¸°', variable=overlap_handling_var, value='cut').grid(row=1, column=2,
                                                                                             sticky='w', padx=5)

# ìµœëŒ€ í™•ì¥ ì œí•œ
max_extension_var = tk.StringVar(value="50")
ttk.Label(timeline_frame, text="ìµœëŒ€ í™•ì¥ìœ¨ (%):").grid(row=2, column=0, sticky='w', padx=5, pady=2)
max_extension_entry = ttk.Entry(timeline_frame, textvariable=max_extension_var, width=10)
max_extension_entry.grid(row=2, column=1, sticky='w', padx=5, pady=2)
ttk.Label(timeline_frame, text="(ì›ë³¸ ëŒ€ë¹„ ìµœëŒ€ í™•ì¥ í—ˆìš© ë¹„ìœ¨)").grid(row=2, column=2, sticky='w', padx=5, pady=2)

# ë²ˆì—­ ì„¤ì • í”„ë ˆì„
translation_frame = ttk.LabelFrame(main_tab, text="ë‹¤êµ­ì–´ ë²ˆì—­ ì„¤ì •")
translation_frame.pack(pady=5, padx=10, fill='x')

# ë²ˆì—­í•  ì–¸ì–´ ì„ íƒ ì²´í¬ë°•ìŠ¤ë“¤
target_languages_frame = ttk.Frame(translation_frame)
target_languages_frame.grid(row=0, column=0, columnspan=4, sticky='w', padx=5, pady=5)

ttk.Label(target_languages_frame, text="ë²ˆì—­í•  ì–¸ì–´:").pack(side=tk.LEFT, padx=(0, 10))

# ì–¸ì–´ë³„ ì²´í¬ë°•ìŠ¤ ë³€ìˆ˜ë“¤
enable_english_var = tk.BooleanVar(value=True)
enable_chinese_var = tk.BooleanVar(value=True)
enable_japanese_var = tk.BooleanVar(value=True)

ttk.Checkbutton(target_languages_frame, text="ğŸ‡ºğŸ‡¸ ì˜ì–´", variable=enable_english_var).pack(side=tk.LEFT, padx=5)
ttk.Checkbutton(target_languages_frame, text="ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´", variable=enable_chinese_var).pack(side=tk.LEFT, padx=5)
ttk.Checkbutton(target_languages_frame, text="ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´", variable=enable_japanese_var).pack(side=tk.LEFT, padx=5)

# ë²ˆì—­ ê¸¸ì´ ë¹„ìœ¨
translation_length_var = tk.StringVar(value="0.6")
ttk.Label(translation_frame, text="ë²ˆì—­ ê¸¸ì´ ë¹„ìœ¨:").grid(row=0, column=0, sticky='w', padx=5, pady=2)
translation_length_entry = ttk.Entry(translation_frame, textvariable=translation_length_var, width=10)
translation_length_entry.grid(row=0, column=1, sticky='w', padx=5, pady=2)
ttk.Label(translation_frame, text="(0.8 = ì›ë³¸ì˜ 80% ê¸¸ì´ë¡œ ì¶•ì•½, 1.0 = ì›ë³¸ ê¸¸ì´ ìœ ì§€)").grid(row=0, column=2, sticky='w', padx=5,
                                                                                 pady=2)

# ìŠ¤ë§ˆíŠ¸ ì••ì¶• ì„¤ì • í”„ë ˆì„
smart_compression_frame = ttk.LabelFrame(main_tab, text="ìŠ¤ë§ˆíŠ¸ ì••ì¶• (AI ê¸¸ì´ ì¡°ì ˆ)")
smart_compression_frame.pack(pady=5, padx=10, fill='x')

# ìŠ¤ë§ˆíŠ¸ ì••ì¶• í™œì„±í™”
enable_smart_compression_var = tk.BooleanVar(value=True)
ttk.Checkbutton(smart_compression_frame, text='ìŠ¤ë§ˆíŠ¸ ì••ì¶• í™œì„±í™” (AI ê¸°ë°˜ ìë™ ê¸¸ì´ ì¡°ì ˆ)',
                variable=enable_smart_compression_var).grid(row=0, column=0, columnspan=3, sticky='w', padx=5, pady=2)

# ì••ì¶• ê°•ë„ ì„¤ì •
compression_level_var = tk.StringVar(value="balanced")
ttk.Label(smart_compression_frame, text="ì••ì¶• ê°•ë„:").grid(row=1, column=0, sticky='w', padx=5, pady=2)
ttk.Radiobutton(smart_compression_frame, text='ë³´ìˆ˜ì ', variable=compression_level_var, value='conservative').grid(row=1,
                                                                                                                column=1,
                                                                                                                sticky='w',
                                                                                                                padx=5)
ttk.Radiobutton(smart_compression_frame, text='ê· í˜•', variable=compression_level_var, value='balanced').grid(row=1,
                                                                                                           column=2,
                                                                                                           sticky='w',
                                                                                                           padx=5)
ttk.Radiobutton(smart_compression_frame, text='ì ê·¹ì ', variable=compression_level_var, value='aggressive').grid(row=1,
                                                                                                              column=3,
                                                                                                              sticky='w',
                                                                                                              padx=5)

# ë¬´ìŒ ì œê±° ì„¤ì •
remove_silence_var = tk.BooleanVar(value=True)
ttk.Checkbutton(smart_compression_frame, text='ê³¼ë„í•œ ë¬´ìŒ êµ¬ê°„ ìë™ ì œê±°',
                variable=remove_silence_var).grid(row=2, column=0, columnspan=2, sticky='w', padx=5, pady=2)

max_silence_var = tk.StringVar(value="300")
ttk.Label(smart_compression_frame, text="ìµœëŒ€ ë¬´ìŒ ê¸¸ì´(ms):").grid(row=2, column=2, sticky='w', padx=5, pady=2)
max_silence_entry = ttk.Entry(smart_compression_frame, textvariable=max_silence_var, width=8)
max_silence_entry.grid(row=2, column=3, sticky='w', padx=5, pady=2)

# ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì²˜ë¦¬ ì„¤ì •
priority_processing_var = tk.BooleanVar(value=True)
ttk.Checkbutton(smart_compression_frame, text='ì¤‘ìš”ë„ ê¸°ë°˜ ì°¨ë“± ì²˜ë¦¬ (ì¤‘ìš”í•œ ëŒ€ì‚¬ëŠ” ëœ ì••ì¶•)',
                variable=priority_processing_var).grid(row=3, column=0, columnspan=3, sticky='w', padx=5, pady=2)

# ë²ˆì—­ í’ˆì§ˆ ì„¤ì •
translation_quality_var = tk.StringVar(value="balanced")
ttk.Label(translation_frame, text="ë²ˆì—­ í’ˆì§ˆ ìš°ì„ ìˆœìœ„:").grid(row=3, column=0, sticky='w', padx=5, pady=2)
ttk.Radiobutton(translation_frame, text='ê°„ê²°í•¨ ìš°ì„ ', variable=translation_quality_var, value='concise').grid(row=3,
                                                                                                          column=1,
                                                                                                          sticky='w',
                                                                                                          padx=5)
ttk.Radiobutton(translation_frame, text='ê· í˜•', variable=translation_quality_var, value='balanced').grid(row=3, column=2,
                                                                                                       sticky='w',
                                                                                                       padx=5)
ttk.Radiobutton(translation_frame, text='ì •í™•ì„± ìš°ì„ ', variable=translation_quality_var, value='accurate').grid(row=3,
                                                                                                           column=3,
                                                                                                           sticky='w',
                                                                                                           padx=5)

# ìŒì„± í•©ì„±í•  ì–¸ì–´ ì„ íƒ
synthesis_lang_frame = ttk.LabelFrame(main_tab, text="ìŒì„± í•©ì„± ì–¸ì–´ ì„ íƒ")
synthesis_lang_frame.pack(pady=5, padx=10, fill='x')

synthesis_language_var = tk.StringVar(value="english")
ttk.Label(synthesis_lang_frame, text="í•©ì„±í•  ì–¸ì–´:").pack(side=tk.LEFT, padx=(5, 10))
ttk.Radiobutton(synthesis_lang_frame, text="ğŸ‡ºğŸ‡¸ ì˜ì–´", variable=synthesis_language_var, value="english").pack(side=tk.LEFT,
                                                                                                           padx=5)
ttk.Radiobutton(synthesis_lang_frame, text="ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´", variable=synthesis_language_var, value="chinese").pack(
    side=tk.LEFT, padx=5)
ttk.Radiobutton(synthesis_lang_frame, text="ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´", variable=synthesis_language_var, value="japanese").pack(
    side=tk.LEFT, padx=5)

# ë²ˆì—­ ìœ í˜• ì„ íƒ (literal/free)
translation_type_var = tk.StringVar(value="free")
ttk.Label(synthesis_lang_frame, text="  |  ë²ˆì—­ ìœ í˜•:").pack(side=tk.LEFT, padx=(20, 5))
ttk.Radiobutton(synthesis_lang_frame, text="ì§ì—­", variable=translation_type_var, value="literal").pack(side=tk.LEFT,
                                                                                                      padx=5)
ttk.Radiobutton(synthesis_lang_frame, text="ì˜ì—­", variable=translation_type_var, value="free").pack(side=tk.LEFT, padx=5)

# ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì • í”„ë ˆì„
memory_frame = ttk.LabelFrame(main_tab, text="ë©”ëª¨ë¦¬ ê´€ë¦¬ (CPU/CUDA)")
memory_frame.pack(pady=5, padx=10, fill='x')

# ë°°ì¹˜ í¬ê¸° ì„¤ì •
batch_size_var = tk.StringVar(value="5")
ttk.Label(memory_frame, text="ë°°ì¹˜ í¬ê¸°:").grid(row=0, column=0, sticky='w', padx=5, pady=2)
batch_size_entry = ttk.Entry(memory_frame, textvariable=batch_size_var, width=10)
batch_size_entry.grid(row=0, column=1, sticky='w', padx=5, pady=2)
ttk.Label(memory_frame, text="(í•œ ë²ˆì— ì²˜ë¦¬í•  ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜, ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì¤„ì´ì„¸ìš”)").grid(row=0, column=2, sticky='w', padx=5, pady=2)

# ë©”ëª¨ë¦¬ ì •ë¦¬ ì£¼ê¸°
memory_cleanup_var = tk.BooleanVar(value=True)
ttk.Checkbutton(memory_frame, text='ì„¸ê·¸ë¨¼íŠ¸ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬ (ëŠë¦¬ì§€ë§Œ ì•ˆì „)', variable=memory_cleanup_var).grid(row=1, column=0,
                                                                                                columnspan=3,
                                                                                                sticky='w', padx=5,
                                                                                                pady=2)

# ë³‘í•© ë²„íŠ¼ ë° ì…ë ¥ë€
ttk.Label(main_tab, text='ì»¤ìŠ¤í…€ ë³‘í•© íƒ€ì´ë°(ms) ë¦¬ìŠ¤íŠ¸ (JSON ë°°ì—´):').pack(pady=(10,0))
merge_entry = ttk.Entry(main_tab, width=80)
merge_entry.pack(pady=2)
ttk.Button(main_tab, text='ë³‘í•© ì‹¤í–‰', command=merge_custom_callback).pack(pady=5)
# ì „ì²´ ë³‘í•© ë²„íŠ¼ ì¶”ê°€
ttk.Button(main_tab, text='ì „ì²´ ë³‘í•©', command=merge_all_segments_callback).pack(pady=5)

# ë¡œê·¸ íƒ­ì— ë¡œê·¸ ë°•ìŠ¤ ì¶”ê°€
log_text = scrolledtext.ScrolledText(log_tab, width=100, height=40,
    font=("Malgun Gothic",10), state='disabled', background='black', foreground='lime')
log_text.pack(padx=5, pady=5, fill='both', expand=True)

# ë©”ì¸ íƒ­ì˜ ë¡œê·¸ ë°•ìŠ¤ëŠ” ì œê±°
# install_log_box = scrolledtext.ScrolledText(main_tab, width=100, height=20,
#     font=("Malgun Gothic",10), state='disabled', background='black', foreground='lime')
# install_log_box.pack(padx=5, pady=5, fill='both', expand=True)
# audio_log_box = scrolledtext.ScrolledText(main_tab, width=100, height=10,
#     font=("Malgun Gothic",10), state='disabled', background='white', foreground='black')
# audio_log_box.pack(padx=5, pady=5, fill='both', expand=True)

frm = ttk.Frame(settings_tab); frm.pack(padx=10, pady=10, fill='x')
labels_k   = ['ìŒì„± ì„ê³„ê°’','ìµœì†Œ ìŒì„±(ms)','ìµœëŒ€ ìŒì„±(s)','ìµœì†Œ ë¬´ìŒ(ms)','ìŒì„± íŒ¨ë”©(ms)']
config_keys= ['threshold','min_speech_duration_ms','max_speech_duration_s','min_silence_duration_ms','speech_pad_ms']
entries = []
for i, key in enumerate(config_keys):
    ttk.Label(frm, text=labels_k[i]).grid(row=i, column=0, sticky='w')
    ent = ttk.Entry(frm); ent.grid(row=i, column=1, sticky='w')
    entries.append(ent)
threshold_entry, min_speech_entry, max_speech_entry, min_silence_entry, pad_entry = entries
ttk.Button(frm, text='ì €ì¥', command=save_config).grid(row=len(entries), column=0, columnspan=2, pady=10)


load_config()
for ent, key in zip(entries, config_keys):
    ent.insert(0, vad_config[key])


# ë¡œê·¸ í ì²˜ë¦¬ë¥¼ ë¡œê·¸ íƒ­ì˜ ë¡œê·¸ ë°•ìŠ¤ì— ì—°ê²°
root.after(200, process_log_queue)
root.mainloop()
