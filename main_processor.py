import os
import threading
import time
from pydub import AudioSegment
from utils import log_message, is_video_file, is_audio_file
from video_processor import process_video_file, combine_processed_audio_with_background, combine_audio_with_video
from whisper_processor import run_full_whisper_processing, run_whisper_directory
from audio_processor import parse_srt_segments, merge_segments_preserve_timing, apply_speaker_based_splitting, \
    split_audio_by_srt, extend_short_segments_for_zeroshot, create_extended_segments_mapping
from batch_cosy import main as cosy_batch
from config import load_vad_config
from batch_translate import SUPPORTED_LANGUAGES


def apply_lip_sync_to_video(video_path, audio_path, output_path, frame_folder=None):
    """
    MuseTalkì„ ì‚¬ìš©í•˜ì—¬ ë¦½ì‹±í¬ ì ìš© (main_processorìš©)
    """
    try:
        import subprocess
        import shutil

        # MuseTalk ë””ë ‰í† ë¦¬ ê²½ë¡œ
        musetalk_dir = os.path.join(os.path.dirname(__file__), 'MuseTalk')

        if not os.path.exists(musetalk_dir):
            log_message("âš ï¸ MuseTalkì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë¦½ì‹±í¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False

        log_message("ğŸ¥ ë¦½ì‹±í¬ ì²˜ë¦¬ ì‹œì‘...")
        log_message(f"   ğŸ“¹ ì…ë ¥ ë¹„ë””ì˜¤: {os.path.basename(video_path)}")
        log_message(f"   ğŸµ ì…ë ¥ ì˜¤ë””ì˜¤: {os.path.basename(audio_path)}")
        log_message(f"   ğŸ’¾ ìµœì¢… ì¶œë ¥ ê²½ë¡œ: {output_path}")
        log_message(f"   ğŸ“‚ MuseTalk ì‘ì—… ë””ë ‰í† ë¦¬: {musetalk_dir}")
        log_message(f"   ğŸ“ MuseTalk ê²°ê³¼ ìƒì„± ìœ„ì¹˜: {os.path.join(musetalk_dir, 'results', 'auto_lip_sync', 'v15')}")

        # ë¹„ë””ì˜¤ë¥¼ 25fpsë¡œ ë³€í™˜
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        temp_video_25fps = os.path.join(os.path.dirname(video_path), f"{base_name}_temp_25fps.mp4")

        log_message("ğŸ”„ ë¹„ë””ì˜¤ë¥¼ 25fpsë¡œ ë³€í™˜ ì¤‘...")
        # FFmpegë¡œ 25fps ë³€í™˜
        ffmpeg_cmd = [
            "ffmpeg", "-y", "-i", video_path,
            "-r", "25", temp_video_25fps
        ]
        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)

        if result.returncode != 0:
            log_message(f"âŒ ë¹„ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {result.stderr}")
            return False

        log_message("âœ… 25fps ë³€í™˜ ì™„ë£Œ")

        # MuseTalk ì„¤ì • íŒŒì¼ ìƒì„±
        config_dir = os.path.join(musetalk_dir, 'configs', 'inference')
        os.makedirs(config_dir, exist_ok=True)

        config_path = os.path.join(config_dir, 'auto_lip_sync_config.yaml')

        # ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        rel_video_path = os.path.relpath(temp_video_25fps, musetalk_dir)
        rel_audio_path = os.path.relpath(audio_path, musetalk_dir)

        # ê°œì„ ëœ ì„¤ì • íŒŒì¼ (ë” ë§ì€ íŒŒë¼ë¯¸í„° í¬í•¨)
        config_content = f"""task_0:
  video_path: "{rel_video_path}"
  audio_path: "{rel_audio_path}"
  bbox_shift: 0
  extra_margin: 5
  parsing_mode: "default"
"""

        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)

        log_message("ğŸ“ MuseTalk ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ")

        # ì…ë ¥ íŒŒì¼ ê²€ì¦
        log_message("ğŸ” ì…ë ¥ íŒŒì¼ ê²€ì¦ ì¤‘...")

        # ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸
        try:
            import subprocess
            video_info_cmd = ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_format", "-show_streams",
                              temp_video_25fps]
            video_info_result = subprocess.run(video_info_cmd, capture_output=True, text=True)
            if video_info_result.returncode == 0:
                import json
                video_info = json.loads(video_info_result.stdout)
                video_duration = float(video_info['format']['duration'])
                log_message(f"   ğŸ“¹ ë¹„ë””ì˜¤ ê¸¸ì´: {video_duration:.2f}ì´ˆ")
                for stream in video_info['streams']:
                    if stream['codec_type'] == 'video':
                        log_message(f"   ğŸ“ í•´ìƒë„: {stream['width']}x{stream['height']}")
                        log_message(f"   ğŸ¬ í”„ë ˆì„ë ˆì´íŠ¸: {stream['r_frame_rate']}")
        except:
            log_message("   âš ï¸ ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸ ì‹¤íŒ¨")

        # ì˜¤ë””ì˜¤ ì •ë³´ í™•ì¸
        try:
            audio_info_cmd = ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_format", audio_path]
            audio_info_result = subprocess.run(audio_info_cmd, capture_output=True, text=True)
            if audio_info_result.returncode == 0:
                audio_info = json.loads(audio_info_result.stdout)
                audio_duration = float(audio_info['format']['duration'])
                log_message(f"   ğŸµ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ")
                if abs(video_duration - audio_duration) > 1.0:
                    log_message(f"   âš ï¸ ê¸¸ì´ ì°¨ì´: {abs(video_duration - audio_duration):.2f}ì´ˆ (1ì´ˆ ì´ìƒ ì°¨ì´)")
        except:
            log_message("   âš ï¸ ì˜¤ë””ì˜¤ ì •ë³´ í™•ì¸ ì‹¤íŒ¨")

        log_message("ğŸ¬ MuseTalk ì‹¤í–‰ ì¤‘... (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        log_message("   - ì–¼êµ´ ê°ì§€ ë° ëœë“œë§ˆí¬ ì¶”ì¶œ")
        log_message("   - ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„")
        log_message("   - ë¦½ì‹±í¬ í”„ë ˆì„ ìƒì„±")

        # MuseTalk ì‹¤í–‰ (ë” ë§ì€ íŒŒë¼ë¯¸í„° í¬í•¨)
        musetalk_cmd = [
            "python", "-m", "scripts.inference",
            "--inference_config", "configs/inference/auto_lip_sync_config.yaml",
            "--result_dir", "results/auto_lip_sync",
            "--unet_model_path", "models/musetalkV15/unet.pth",
            "--unet_config", "models/musetalkV15/musetalk.json",
            "--version", "v15",
            "--bbox_shift", "0",
            "--extra_margin", "5"
        ]

        # MuseTalk ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
        result = subprocess.run(
            musetalk_cmd,
            cwd=musetalk_dir,
            capture_output=True,
            text=True
        )

        # MuseTalk ì‹¤í–‰ ê²°ê³¼ ìƒì„¸ ë¡œê·¸
        log_message(f"ğŸ” MuseTalk ì‹¤í–‰ ê²°ê³¼:")
        log_message(f"   ë°˜í™˜ ì½”ë“œ: {result.returncode}")

        if result.stdout:
            log_message(f"   í‘œì¤€ ì¶œë ¥:")
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    log_message(f"     {line}")

        if result.stderr:
            log_message(f"   ì˜¤ë¥˜ ì¶œë ¥:")
            for line in result.stderr.strip().split('\n'):
                if line.strip():
                    log_message(f"     {line}")

        if result.returncode != 0:
            log_message(f"âŒ MuseTalk ì‹¤í–‰ ì‹¤íŒ¨:")
            log_message(f"   ë°˜í™˜ ì½”ë“œ: {result.returncode}")
            if not result.stderr and not result.stdout:
                log_message("   ì¶œë ¥ ì—†ìŒ - í™˜ê²½ ì„¤ì • ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            return False

        log_message("âœ… MuseTalk ì²˜ë¦¬ ì™„ë£Œ")
        log_message("ğŸ” ë¦½ì‹±í¬ ê²°ê³¼ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")

        # ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        result_dir = os.path.join(musetalk_dir, 'results', 'auto_lip_sync', 'v15')

        log_message(f"   ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {result_dir}")

        if not os.path.exists(result_dir):
            log_message(f"âŒ MuseTalk ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
            log_message(f"   ê²½ë¡œ: {result_dir}")
            # ìƒìœ„ ë””ë ‰í† ë¦¬ë“¤ í™•ì¸
            parent_dir = os.path.join(musetalk_dir, 'results')
            if os.path.exists(parent_dir):
                try:
                    subdirs = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]
                    log_message(f"   results ë‚´ ì„œë¸Œë””ë ‰í† ë¦¬: {subdirs}")
                except:
                    log_message("   results ë””ë ‰í† ë¦¬ ì ‘ê·¼ ë¶ˆê°€")
            else:
                log_message("   results ë””ë ‰í† ë¦¬ë„ ì—†ìŒ")
            return False

        # ìƒì„±ëœ íŒŒì¼ ì°¾ê¸°
        try:
            all_files = os.listdir(result_dir)
            log_message(f"   ğŸ“„ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼: {all_files}")

            result_files = []
            for file in all_files:
                if file.endswith('.mp4'):
                    file_path = os.path.join(result_dir, file)
                    file_size = os.path.getsize(file_path)
                    result_files.append(file_path)
                    log_message(f"   ğŸ¥ MP4 íŒŒì¼ ë°œê²¬: {file} ({file_size} bytes)")
        except Exception as e:
            log_message(f"âŒ ë””ë ‰í† ë¦¬ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            return False

        if not result_files:
            log_message("âŒ ë¦½ì‹±í¬ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            log_message("   ê°€ëŠ¥í•œ ì›ì¸:")
            log_message("   1. MuseTalk FFmpeg í•©ì„± ë‹¨ê³„ ì‹¤íŒ¨")
            log_message("   2. ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨")
            log_message("   3. ì˜¤ë””ì˜¤ ê¸¸ì´ì™€ ë¹„ë””ì˜¤ ê¸¸ì´ ë¶ˆì¼ì¹˜")
            log_message("   4. ë©”ëª¨ë¦¬ ë¶€ì¡±")
            log_message("   5. CUDA/GPU ë¬¸ì œ")

            # ì„¤ì • íŒŒì¼ ë‚´ìš© í™•ì¸
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config_content_check = f.read()
                log_message("   ğŸ“ ì‚¬ìš©ëœ ì„¤ì •:")
                for line in config_content_check.strip().split('\n'):
                    log_message(f"     {line}")
            except:
                log_message("   ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")

            return False

        log_message(f"âœ… ë¦½ì‹±í¬ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {os.path.basename(result_files[0])}")

        # ì²« ë²ˆì§¸ ê²°ê³¼ íŒŒì¼ì„ ì¶œë ¥ ê²½ë¡œë¡œ ë³µì‚¬
        log_message("ğŸ“ ìµœì¢… ì¶œë ¥ íŒŒì¼ë¡œ ë³µì‚¬ ì¤‘...")
        log_message(f"   ğŸ”„ ë³µì‚¬: {result_files[0]}")
        log_message(f"   ğŸ“ ëª©ì ì§€: {output_path}")
        shutil.copy2(result_files[0], output_path)

        # MuseTalk ê²°ê³¼ íŒŒì¼ ì •ë¦¬ (ì„ íƒì‚¬í•­)
        try:
            os.remove(result_files[0])
            log_message("ğŸ—‘ï¸ MuseTalk ì„ì‹œ ê²°ê³¼ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except:
            log_message("âš ï¸ MuseTalk ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ (ê¶Œí•œ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ)")

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(temp_video_25fps):
            os.remove(temp_video_25fps)
            log_message("ğŸ—‘ï¸ 25fps ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

        log_message(f"âœ… ë¦½ì‹±í¬ ì™„ë£Œ!")
        log_message(f"   ğŸ“ ìµœì¢… ìœ„ì¹˜: {output_path}")
        log_message(f"   ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / (1024 * 1024):.1f}MB")
        return True

    except Exception as e:
        log_message(f"âŒ ë¦½ì‹±í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        log_message(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def process_complete_pipeline(input_file, settings):
    """
    ì™„ì „í•œ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

    í”Œë¡œìš°:
    1. ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œ
    2. ìŒì„±ì—ì„œ ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬
    3. ë³´ì»¬ë§Œ STT â†’ ë²ˆì—­ â†’ TTS â†’ ë³‘í•©
    4. ì²˜ë¦¬ëœ ë³´ì»¬ê³¼ ë°°ê²½ìŒ ì¬í•©ì„±
    5. ìµœì¢… ì˜ìƒê³¼ ìŒì„± í•©ì„±
    """
    try:
        # ë””ë²„ê·¸: ì„¤ì • í™•ì¸
        log_message(f"ğŸ”§ ì²˜ë¦¬ ì„¤ì • í™•ì¸:")
        log_message(f"  - ë¦½ì‹±í¬ í™œì„±í™”: {settings.get('enable_lip_sync', False)}")
        log_message(f"  - ì„ íƒëœ ì–¸ì–´: {settings.get('selected_languages', [])}")

        base_name = os.path.splitext(os.path.basename(input_file))[0]
        output_base_dir = os.path.join(os.getcwd(), 'video_output', base_name)
        os.makedirs(output_base_dir, exist_ok=True)

        log_message(f"ğŸ¬ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {input_file}")

        # Step 1: ì˜ìƒ ì²˜ë¦¬ (ìŒì„± ì¶”ì¶œ + ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬)
        log_message("ğŸ“¹ Step 1: ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œ ë° ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬")
        extracted_audio, vocals_path, background_path, original_video = process_video_file(
            input_file, output_base_dir
        )

        if not vocals_path or not background_path:
            log_message("âŒ ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬ ì‹¤íŒ¨, íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
            return

        # Step 2: ë³´ì»¬ íŒŒì¼ë¡œ STT ì²˜ë¦¬
        log_message("ğŸ¤ Step 2: ë³´ì»¬ ìŒì„±ìœ¼ë¡œ STT ì²˜ë¦¬")
        vad_config = load_vad_config()
        output_dir, segments, orig_duration = run_full_whisper_processing(vocals_path, vad_config)

        if not output_dir or not segments:
            log_message("âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨, íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
            return

        # í™”ì ê¸°ë°˜ ë¶„í•  ì ìš© (í™œì„±í™”ëœ ê²½ìš°)
        if settings.get('enable_speaker_splitting', False):
            log_message("ğŸ—£ï¸ í™”ì ê¸°ë°˜ ë¶„í•  ì ìš© ì¤‘...")
            base_name = os.path.splitext(os.path.basename(vocals_path))[0]
            srt_path = os.path.join(output_dir, f"{base_name}{os.path.splitext(vocals_path)[1]}.srt")
            segments, orig_duration = apply_speaker_based_splitting(
                vocals_path,
                srt_path,
                output_dir,
                True
            )

        if not output_dir or not segments:
            log_message("âŒ í™”ì ë¶„í•  ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # Step 3: í…ìŠ¤íŠ¸ ë²ˆì—­ ë° ìŒì„± í•©ì„±
        log_message("ğŸ”„ Step 3: í…ìŠ¤íŠ¸ ë²ˆì—­ ë° ìŒì„± í•©ì„±")

        # ë²ˆì—­ ì„¤ì • êµ¬ì„±
        translation_settings = {
            'translation_length': settings.get('translation_length', 0.8),
            'quality_mode': settings.get('quality_mode', 'balanced'),
            'selected_languages': settings.get('selected_languages', ['english'])
        }

        # Whisper ë””ë ‰í† ë¦¬ ì²˜ë¦¬ (ë²ˆì—­ í¬í•¨)
        selected_languages = run_whisper_directory(output_dir, translation_settings)

        if not selected_languages:
            log_message("âŒ ë²ˆì—­ ì²˜ë¦¬ ì‹¤íŒ¨, íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
            return

        # ê° ì–¸ì–´ë³„ë¡œ ìŒì„± í•©ì„±
        processed_vocals = {}

        for lang in selected_languages:
            lang_name = SUPPORTED_LANGUAGES[lang]['name'].lower()
            trans_type = "free"
            text_dir = os.path.join(output_dir, 'txt', lang_name, trans_type)

            if not os.path.exists(text_dir):
                log_message(f"â­ï¸ {SUPPORTED_LANGUAGES[lang]['name']} {trans_type} í…ìŠ¤íŠ¸ ì—†ìŒ, ê±´ë„ˆë›°ê¸°")
                continue

            log_message(f"ğŸ”Š {SUPPORTED_LANGUAGES[lang]['name']} ({trans_type}) ìŒì„± í•©ì„± ì‹œì‘...")

            # CosyVoice2 í•©ì„± í˜¸ì¶œ
            cosy_out = os.path.join(output_dir, 'cosy_output', lang_name, trans_type)
            os.makedirs(cosy_out, exist_ok=True)

            # 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ (ì œë¡œìƒ· ê°œì„ ìš©)
            if settings.get('enable_3sec_extension', True):
                log_message("ğŸ”„ ì œë¡œìƒ· í•©ì„±ì„ ìœ„í•œ 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì¤‘...")
                from audio_processor import extend_short_segments_for_zeroshot, create_extended_segments_mapping
                extended_wav_dir = extend_short_segments_for_zeroshot(output_dir, min_duration_ms=3000)

                if extended_wav_dir:
                    # í™•ì¥ ë§¤í•‘ ì •ë³´ ìƒì„±
                    mapping_info = create_extended_segments_mapping(output_dir, extended_wav_dir)
                    log_message(f"ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì™„ë£Œ: {len(mapping_info.get('segments_info', []))}ê°œ íŒŒì¼ ì²˜ë¦¬")

                    # í™•ì¥ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•©ì„±
                    synthesis_audio_dir = extended_wav_dir
                else:
                    # í™•ì¥ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                    log_message("âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì‹¤íŒ¨, ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©")
                    synthesis_audio_dir = os.path.join(output_dir, 'wav')
            else:
                # ì„¤ì • ë¹„í™œì„±í™” ì‹œ ì›ë³¸ ì‚¬ìš©
                synthesis_audio_dir = os.path.join(output_dir, 'wav')

            # ë©”ëª¨ë¦¬ ì •ë¦¬ (í•©ì„± ì „)
            import gc
            gc.collect()

            try:
                # UI ì„¤ì •ê°’ ì ìš©
                enable_instruct = settings.get('enable_instruct', False)
                manual_command = settings.get('manual_command', None)

                log_message(f"  ì–¸ì–´: {SUPPORTED_LANGUAGES[lang]['name']}")
                log_message(f"  ë²ˆì—­ ìœ í˜•: {trans_type}")
                log_message(f"  Instruct2 í™œì„±í™”: {enable_instruct}")
                if manual_command:
                    log_message(f"  ìˆ˜ë™ ëª…ë ¹ì–´: {manual_command}")

                # CosyVoice2 ë°°ì¹˜ í•©ì„± (ì–¸ì–´ ì •ë³´ í¬í•¨)
                cosy_batch(
                    audio_dir=synthesis_audio_dir,
                    prompt_text_dir=os.path.join(output_dir, 'txt', 'ko'),
                    text_dir=text_dir,
                    out_dir=cosy_out,
                    enable_instruct=enable_instruct,
                    manual_command=manual_command,
                    target_language=lang
                )

                log_message(f"âœ… {SUPPORTED_LANGUAGES[lang]['name']} ({trans_type}) í•©ì„± ì™„ë£Œ")

                # ì‹¤ì œ í•©ì„± íŒŒì¼ë“¤ì€ zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ì— ì €ì¥ë¨
                actual_synthesis_dir = os.path.join(cosy_out, 'zero_shot')

                # ë³‘í•©
                merged_path = os.path.join(output_dir, f"{base_name}_{lang_name}_merged.wav")
                merge_segments_preserve_timing(
                    segments,
                    orig_duration,  # ì´ë¯¸ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ì´ë¯€ë¡œ * 1000 ì œê±°
                    actual_synthesis_dir,  # zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ ì°¸ì¡°
                    merged_path,
                    length_handling=settings.get('length_handling', 'preserve'),
                    overlap_handling=settings.get('overlap_handling', 'fade'),
                    max_extension=settings.get('max_extension', 50),
                    enable_smart_compression=settings.get('enable_smart_compression', True)
                )

                processed_vocals[lang] = merged_path
                log_message(f"âœ… {lang_name} ë³´ì»¬ ë³‘í•© ì™„ë£Œ: {merged_path}")

            except Exception as e:
                log_message(f"âŒ {SUPPORTED_LANGUAGES[lang]['name']} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue

            # í•©ì„± ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()

        # Step 4: ê° ì–¸ì–´ë³„ë¡œ ë³´ì»¬+ë°°ê²½ìŒ í•©ì„± ë° ìµœì¢… ì˜ìƒ ìƒì„±
        log_message("ğŸµ Step 4: ë³´ì»¬ê³¼ ë°°ê²½ìŒ í•©ì„± ë° ìµœì¢… ì˜ìƒ ìƒì„±")

        final_videos = []

        for lang_code, processed_vocal_path in processed_vocals.items():
            lang_name = SUPPORTED_LANGUAGES[lang_code]['name'].lower()
            lang_display_name = SUPPORTED_LANGUAGES[lang_code]['name']

            # ë³´ì»¬ + ë°°ê²½ìŒ í•©ì„±
            combined_audio_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_combined.wav")

            success = combine_processed_audio_with_background(
                processed_vocal_path,
                background_path,
                combined_audio_path,
                vocals_volume=settings.get('vocals_volume', 1.0),
                background_volume=settings.get('background_volume', 0.8)
            )

            if success:
                # ìµœì¢… ì˜ìƒ ìƒì„±
                final_video_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_final.mp4")

                video_success = combine_audio_with_video(
                    original_video,
                    combined_audio_path,
                    final_video_path
                )

                if video_success:
                    final_videos.append((lang_name, final_video_path))
                    log_message(f"âœ… {lang_name} ìµœì¢… ì˜ìƒ ì™„ë£Œ: {final_video_path}")
                else:
                    log_message(f"âŒ {lang_name} ì˜ìƒ í•©ì„± ì‹¤íŒ¨")
            else:
                log_message(f"âŒ {lang_name} ìŒì„± í•©ì„± ì‹¤íŒ¨")

        # Step 5: ë¦½ì‹±í¬ ì²˜ë¦¬ (ëª¨ë“  ì–¸ì–´ì— ëŒ€í•´)
        if settings.get('enable_lip_sync', False):
            log_message("ğŸ—£ï¸ ë¦½ì‹±í¬ ì²˜ë¦¬ í™œì„±í™”ë¨. ëª¨ë“  ì–¸ì–´ ë²„ì „ì— ë¦½ì‹±í¬ ì ìš© ì¤‘...")
            log_message(f"   ğŸ¯ ì²˜ë¦¬ ëŒ€ìƒ ì–¸ì–´: {len(processed_vocals)}ê°œ")
            lip_sync_videos = []

            for idx, (lang_code, processed_vocal_path) in enumerate(processed_vocals.items(), 1):
                lang_name = SUPPORTED_LANGUAGES[lang_code]['name'].lower()
                lang_display_name = SUPPORTED_LANGUAGES[lang_code]['name']

                # í•´ë‹¹ ì–¸ì–´ì˜ ê¸°ë³¸ ìµœì¢… ì˜ìƒ ê²½ë¡œ
                regular_video_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_final.mp4")

                # ë¦½ì‹±í¬ìš© ì¶œë ¥ ê²½ë¡œ ìƒì„±
                lip_sync_output_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_final_lipsynced.mp4")

                log_message(f"ğŸ¬ [{idx}/{len(processed_vocals)}] {lang_display_name} ë¦½ì‹±í¬ ì²˜ë¦¬ ì‹œì‘...")
                log_message(f"   ğŸ“¹ ê¸°ë³¸ ì˜ìƒ: {os.path.basename(regular_video_path)}")
                log_message(f"   ğŸµ ìŒì„± íŒŒì¼: {os.path.basename(processed_vocal_path)}")

                # ê¸°ë³¸ ì˜ìƒì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                if not os.path.exists(regular_video_path):
                    log_message(f"âŒ {lang_display_name} ê¸°ë³¸ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
                    log_message(f"   ê²½ë¡œ: {regular_video_path}")
                    continue

                # ë¦½ì‹±í¬ ì²˜ë¦¬ (ê¸°ë³¸ ì˜ìƒ + í•´ë‹¹ ì–¸ì–´ ìŒì„±)
                log_message(f"âš™ï¸ {lang_display_name} MuseTalk ì²˜ë¦¬ ì¤‘...")
                start_time = time.time()

                if apply_lip_sync_to_video(regular_video_path, processed_vocal_path, lip_sync_output_path):
                    end_time = time.time()
                    processing_time = int(end_time - start_time)

                    lip_sync_videos.append((lang_name, lip_sync_output_path))
                    log_message(f"âœ… {lang_display_name} ë¦½ì‹±í¬ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {processing_time}ì´ˆ)")
                    log_message(f"   ğŸ’¾ ì¶œë ¥: {os.path.basename(lip_sync_output_path)}")
                else:
                    end_time = time.time()
                    processing_time = int(end_time - start_time)
                    log_message(f"âŒ {lang_display_name} ë¦½ì‹±í¬ ì²˜ë¦¬ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {processing_time}ì´ˆ)")

                # ì§„í–‰ë¥  í‘œì‹œ
                if len(processed_vocals) > 1:
                    progress_percent = (idx / len(processed_vocals)) * 100
                    log_message(f"ğŸ“Š ë¦½ì‹±í¬ ì§„í–‰ë¥ : {progress_percent:.1f}% ({idx}/{len(processed_vocals)})")

            # ë¦½ì‹±í¬ ê²°ê³¼ ìš”ì•½
            if lip_sync_videos:
                log_message("ğŸ‰ ëª¨ë“  ì–¸ì–´ ë¦½ì‹±í¬ ì˜ìƒ ìƒì„± ì™„ë£Œ:")
                log_message(f"   âœ… ì„±ê³µ: {len(lip_sync_videos)}ê°œ")
                log_message(f"   âŒ ì‹¤íŒ¨: {len(processed_vocals) - len(lip_sync_videos)}ê°œ")
                for lang_name, video_path in lip_sync_videos:
                    log_message(f"   ğŸ—£ï¸ {lang_name} ë¦½ì‹±í¬: {os.path.basename(video_path)}")
            else:
                log_message("âŒ ëª¨ë“  ì–¸ì–´ ë¦½ì‹±í¬ ì˜ìƒ ìƒì„± ì‹¤íŒ¨")
                log_message("   ì›ì¸: ê¸°ë³¸ ì˜ìƒ ë˜ëŠ” ìŒì„± íŒŒì¼ ëˆ„ë½, MuseTalk ì²˜ë¦¬ ì˜¤ë¥˜ ë“±")

        # ì™„ë£Œ ë©”ì‹œì§€
        if final_videos:
            log_message("ğŸ‰ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            log_message("ğŸ“ ìƒì„±ëœ ìµœì¢… ì˜ìƒë“¤:")
            for lang_name, video_path in final_videos:
                log_message(f"   ğŸ¬ {lang_name} (ê¸°ë³¸): {video_path}")

            # ë¦½ì‹±í¬ ì˜ìƒì´ ìˆë‹¤ë©´ í•¨ê»˜ í‘œì‹œ
            if settings.get('enable_lip_sync', False) and 'lip_sync_videos' in locals():
                log_message("ğŸ“ ìƒì„±ëœ ë¦½ì‹±í¬ ì˜ìƒë“¤:")
                for lang_name, video_path in lip_sync_videos:
                    log_message(f"   ğŸ—£ï¸ {lang_name} (ë¦½ì‹±í¬): {os.path.basename(video_path)}")
        else:
            log_message("âŒ ìµœì¢… ì˜ìƒ ìƒì„± ì‹¤íŒ¨")

    except Exception as e:
        log_message(f"ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        log_message(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")


def process_audio_only_pipeline(input_file, settings):
    """ê¸°ì¡´ ìŒì„± íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ì›ë³¸ ê¸°ëŠ¥ ìœ ì§€)"""
    try:
        log_message("ğŸµ ìŒì„± íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")

        vad_config = load_vad_config()
        output_dir, segments, orig_duration = run_full_whisper_processing(input_file, vad_config)

        if not output_dir or not segments:
            log_message("âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # í™”ì ê¸°ë°˜ ë¶„í•  ì ìš© (í™œì„±í™”ëœ ê²½ìš°)
        if settings.get('enable_speaker_splitting', False):
            log_message("ğŸ—£ï¸ í™”ì ê¸°ë°˜ ë¶„í•  ì ìš© ì¤‘...")
            base_name = os.path.splitext(os.path.basename(input_file))[0]
            srt_path = os.path.join(output_dir, f"{base_name}{os.path.splitext(input_file)[1]}.srt")
            segments, total_duration = apply_speaker_based_splitting(
                input_file,
                srt_path,
                output_dir,
                True
            )
        else:
            base_name = os.path.splitext(os.path.basename(input_file))[0]
            srt_path = os.path.join(output_dir, f"{base_name}{os.path.splitext(input_file)[1]}.srt")
            segments = parse_srt_segments(srt_path)
            orig_audio = AudioSegment.from_file(input_file)
            original_duration_ms = len(orig_audio)

        if not output_dir or not segments:
            log_message("âŒ í™”ì ë¶„í•  ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # ë²ˆì—­ ì„¤ì • êµ¬ì„±
        translation_settings = {
            'translation_length': settings.get('translation_length', 0.8),
            'quality_mode': settings.get('quality_mode', 'balanced'),
            'selected_languages': settings.get('selected_languages', ['english'])
        }

        # Whisper ë””ë ‰í† ë¦¬ ì²˜ë¦¬ (ë²ˆì—­ í¬í•¨)
        selected_languages = run_whisper_directory(output_dir, translation_settings)

        if not selected_languages:
            log_message("âŒ ë²ˆì—­ ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # ê° ì–¸ì–´ë³„ë¡œ ìŒì„± í•©ì„± ë° ë³‘í•©
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        input_ext = os.path.splitext(input_file)[1]
        srt_path = os.path.join(output_dir, f"{base_name}{input_ext}.srt")
        segments = parse_srt_segments(srt_path)
        orig_audio = AudioSegment.from_file(input_file)
        original_duration_ms = len(orig_audio)

        for lang in selected_languages:
            lang_name = SUPPORTED_LANGUAGES[lang]['name'].lower()
            trans_type = "free"
            text_dir = os.path.join(output_dir, 'txt', lang_name, trans_type)

            if not os.path.exists(text_dir):
                continue

            cosy_out = os.path.join(output_dir, 'cosy_output', lang_name, trans_type)
            os.makedirs(cosy_out, exist_ok=True)

            # 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ (ì œë¡œìƒ· ê°œì„ ìš©)
            if settings.get('enable_3sec_extension', True):
                log_message("ğŸ”„ ì œë¡œìƒ· í•©ì„±ì„ ìœ„í•œ 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì¤‘...")
                from audio_processor import extend_short_segments_for_zeroshot, create_extended_segments_mapping
                extended_wav_dir = extend_short_segments_for_zeroshot(output_dir, min_duration_ms=3000)

                if extended_wav_dir:
                    # í™•ì¥ ë§¤í•‘ ì •ë³´ ìƒì„±
                    mapping_info = create_extended_segments_mapping(output_dir, extended_wav_dir)
                    log_message(f"ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì™„ë£Œ: {len(mapping_info.get('segments_info', []))}ê°œ íŒŒì¼ ì²˜ë¦¬")

                    # í™•ì¥ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•©ì„±
                    synthesis_audio_dir = extended_wav_dir
                else:
                    # í™•ì¥ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                    log_message("âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì‹¤íŒ¨, ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©")
                    synthesis_audio_dir = os.path.join(output_dir, 'wav')
            else:
                # ì„¤ì • ë¹„í™œì„±í™” ì‹œ ì›ë³¸ ì‚¬ìš©
                synthesis_audio_dir = os.path.join(output_dir, 'wav')

            # CosyVoice2 í•©ì„±
            try:
                cosy_batch(
                    audio_dir=synthesis_audio_dir,
                    prompt_text_dir=os.path.join(output_dir, 'txt', 'ko'),
                    text_dir=text_dir,
                    out_dir=cosy_out,
                    enable_instruct=settings.get('enable_instruct', False),
                    manual_command=settings.get('manual_command', None),
                    target_language=lang
                )

                log_message(f"âœ… {lang_name} ({trans_type}) í•©ì„± ì™„ë£Œ")

                # ì‹¤ì œ í•©ì„± íŒŒì¼ë“¤ì€ zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ì— ì €ì¥ë¨
                actual_synthesis_dir = os.path.join(cosy_out, 'zero_shot')

                # ë³‘í•©
                merged_path = os.path.join(output_dir, f"{base_name}_{lang_name}_merged.wav")
                merge_segments_preserve_timing(
                    segments,
                    original_duration_ms,
                    actual_synthesis_dir,  # zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ ì°¸ì¡°
                    merged_path,
                    length_handling=settings.get('length_handling', 'preserve'),
                    overlap_handling=settings.get('overlap_handling', 'fade'),
                    max_extension=settings.get('max_extension', 50),
                    enable_smart_compression=settings.get('enable_smart_compression', True)
                )

                log_message(f"âœ… {lang_name} ì²˜ë¦¬ ì™„ë£Œ: {merged_path}")

            except Exception as e:
                log_message(f"âŒ {lang_name} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        log_message("ğŸµ ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")

    except Exception as e:
        log_message(f"ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")


def start_processing_with_settings(input_file, settings):
    """íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°"""

    def worker():
        try:
            if is_video_file(input_file):
                log_message("ğŸ¬ ì˜ìƒ íŒŒì¼ ê°ì§€ - ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
                process_complete_pipeline(input_file, settings)
            elif is_audio_file(input_file):
                log_message("ğŸµ ìŒì„± íŒŒì¼ ê°ì§€ - ìŒì„± ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
                process_audio_only_pipeline(input_file, settings)
            else:
                log_message("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
        except Exception as e:
            log_message(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    threading.Thread(target=worker, daemon=True).start()
