from batch_translate import SUPPORTED_LANGUAGES
from datetime import datetime
import subprocess
import shutil
import gc
import os
import threading
import time
from pydub import AudioSegment
from utils import log_message, is_video_file, is_audio_file
from video_processor import process_video_file, combine_processed_audio_with_background, combine_audio_with_video
from whisper_processor import run_full_whisper_processing, run_whisper_directory
from audio_processor import parse_srt_segments, merge_segments_preserve_timing, apply_speaker_based_splitting, \
    split_audio_by_srt, extend_short_segments_for_zeroshot, create_extended_segments_mapping
from config import load_vad_config
from batch_cosy import main as cosy_batch

# ğŸ”¥ ìˆ˜ì •ëœ main_processor.py íŒŒì¼ ì‹ë³„ì - ì „ì²˜ë¦¬ ì™„ì „ ì œê±° ë²„ì „ ğŸ”¥
print("ğŸ”¥ğŸ”¥ğŸ”¥ MODIFIED main_processor.py LOADED - ì „ì²˜ë¦¬ ì™„ì „ ì œê±° ë²„ì „ ğŸ”¥ğŸ”¥ğŸ”¥")


def apply_lip_sync_to_video(video_path, audio_path, output_path, frame_folder=None):
    """
    LatentSyncë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦½ì‹±í¬ ì ìš© (main_processorìš©)
    """
    try:
        # LatentSync ë””ë ‰í† ë¦¬ ê²½ë¡œ
        latentsync_dir = os.path.join(os.path.dirname(__file__), 'LatentSync')

        if not os.path.exists(latentsync_dir):
            log_message("âš ï¸ LatentSyncê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë¦½ì‹±í¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False

        log_message("ğŸ¥ ë¦½ì‹±í¬ ì²˜ë¦¬ ì‹œì‘...")
        log_message(f"   ğŸ“¹ ì…ë ¥ ë¹„ë””ì˜¤: {os.path.basename(video_path)}")
        log_message(f"   ğŸµ ì…ë ¥ ì˜¤ë””ì˜¤: {os.path.basename(audio_path)}")
        log_message(f"   ğŸ’¾ ìµœì¢… ì¶œë ¥ ê²½ë¡œ: {output_path}")
        log_message(f"   ğŸ“‚ LatentSync ì‘ì—… ë””ë ‰í† ë¦¬: {latentsync_dir}")

        # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        env = os.environ.copy()
        env['PYTHONPATH'] = latentsync_dir

        # ì…ë ¥ íŒŒì¼ ê²€ì¦
        log_message("ğŸ” ì…ë ¥ íŒŒì¼ ê²€ì¦ ì¤‘...")

        # ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸
        try:
            video_info_cmd = ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_format", "-show_streams",
                              video_path]
            video_info_result = subprocess.run(video_info_cmd, capture_output=True, text=True)
            if video_info_result.returncode == 0:
                import json
                video_info = json.loads(video_info_result.stdout)
                video_duration = float(video_info['format']['duration'])
                log_message(f"   ğŸ“¹ ë¹„ë””ì˜¤ ê¸¸ì´: {video_duration:.2f}ì´ˆ")
                for stream in video_info['streams']:
                    if stream['codec_type'] == 'video':
                        log_message(f"   ğŸ“ í•´ìƒë„: {stream['width']}x{stream['height']}")
                        log_message(f"   ğŸ¬ í”„ë ˆì„ë ˆì´íŠ¸: {stream['r_frame_rate']}")
                        break
        except:
            log_message("âš ï¸ ì…ë ¥ íŒŒì¼ ê²€ì¦ ì˜¤ë¥˜")

        # ì˜¤ë””ì˜¤ ì •ë³´ í™•ì¸
        try:
            audio_info_cmd = ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_format", audio_path]
            audio_info_result = subprocess.run(audio_info_cmd, capture_output=True, text=True)
            if audio_info_result.returncode == 0:
                import json
                audio_info = json.loads(audio_info_result.stdout)
                audio_duration = float(audio_info['format']['duration'])
                log_message(f"   ğŸµ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ")
                if 'video_duration' in locals() and abs(video_duration - audio_duration) > 1.0:
                    log_message(f"   âš ï¸ ê¸¸ì´ ì°¨ì´: {abs(video_duration - audio_duration):.2f}ì´ˆ (1ì´ˆ ì´ìƒ ì°¨ì´)")
        except:
            log_message("   âš ï¸ ì˜¤ë””ì˜¤ ì •ë³´ í™•ì¸ ì‹¤íŒ¨")

        # ì „ì²˜ë¦¬ ê±´ë„ˆë›°ê¸° - ê°•ì œë¡œ ì›ë³¸ ë¹„ë””ì˜¤ ì‚¬ìš©
        log_message("ğŸ¬ LatentSync ì²˜ë¦¬ ì‹œì‘")
        log_message("ğŸ”§ Step 1: LatentSync ì „ì²˜ë¦¬ (ì™„ì „íˆ ê±´ë„ˆë›°ê¸°)")
        log_message("   â­ï¸ ì „ì²˜ë¦¬ ì—†ì´ ì›ë³¸ 25fps ë¹„ë””ì˜¤ë¡œ ë°”ë¡œ ë¦½ì‹±í¬ ì¶”ë¡  ì‹¤í–‰")
        log_message("   ğŸ’¡ ì´ìœ : ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì™„ì „íˆ ë¹„í™œì„±í™”")
        log_message("   ğŸš€ ì›ë³¸ ë¹„ë””ì˜¤ë¡œë„ ë¦½ì‹±í¬ í’ˆì§ˆ í™•ì¸ë¨")

        # ì›ë³¸ 25fps ë¹„ë””ì˜¤ ê²½ë¡œ ì„¤ì • (ì „ì²˜ë¦¬ ì™„ì „ ê±´ë„ˆë›°ê¸°)
        abs_video_path = os.path.abspath(video_path)

        # Step 2: ì¶”ë¡  ë‹¨ê³„
        log_message("ğŸš€ Step 2: LatentSync ì¶”ë¡  (ë¦½ì‹±í¬ ìƒì„±)")
        log_message("   - ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ (Whisper)")
        log_message("   - ë¦½ì‹±í¬ í”„ë ˆì„ ìƒì„± (Diffusion)")

        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¸ (v1.6 ìš°ì„  í™•ì¸ - Gradioì™€ ë™ì¼í•œ ë¡œì§)
        checkpoint_path_v16 = os.path.join(latentsync_dir, "checkpoints_v1.6", "latentsync_unet.pt")
        checkpoint_path_default = os.path.join(latentsync_dir, "checkpoints", "latentsync_unet.pt")

        if os.path.exists(checkpoint_path_v16):
            checkpoint_path = checkpoint_path_v16
            log_message("âœ… LatentSync 1.6 ì „ìš© ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš© (gradio_app.pyì™€ ë™ì¼)")
        elif os.path.exists(checkpoint_path_default):
            checkpoint_path = checkpoint_path_default
            log_message("âœ… LatentSync ê¸°ë³¸ ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš©")
        else:
            log_message(f"âŒ LatentSync ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
            log_message(f"   í™•ì¸í•œ ê²½ë¡œ 1: {checkpoint_path_v16}")
            log_message(f"   í™•ì¸í•œ ê²½ë¡œ 2: {checkpoint_path_default}")
            log_message("   ğŸ’¡ í•´ê²° ë°©ë²•:")
            log_message("   1. LatentSync í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: cd LatentSync && source setup_env.sh")
            log_message(
                "   2. ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ: huggingface-cli download ByteDance/LatentSync-1.6 latentsync_unet.pt --local-dir checkpoints_v1.6"
            )
            return False

        # ì²´í¬í¬ì¸íŠ¸ ë²„ì „ ê°ì§€ ë° ì„¤ì • (gradio_app.pyì™€ ë™ì¼í•œ ë¡œì§)
        if "checkpoints_v1.6" in checkpoint_path:  # 1.6 ë²„ì „ ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš© ì¤‘
            model_version = "1.6"
            config_path = os.path.join(latentsync_dir, "configs", "unet", "stage2_512.yaml")
            if not os.path.exists(config_path):
                config_path = os.path.join(latentsync_dir, "configs", "unet", "stage2.yaml")
            expected_vram = "18GB"
            inference_steps = "30"  # gradio_app.py ê¸°ë³¸ê°’
            guidance_scale = "1.5"  # gradio_app.py ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€ê²½
            log_message("ğŸ¯ LatentSync 1.6 ëª¨ë¸ ê°ì§€ (ê³ í•´ìƒë„ 512x512) - gradio_app.pyì™€ ë™ì¼")
            log_message(f"   - ì„¤ì • íŒŒì¼: {os.path.basename(config_path)}")
            log_message(f"   - DeepCache: í™œì„±í™” (ì†ë„ í–¥ìƒ)")
        else:  # ê¸°ë³¸ ì²´í¬í¬ì¸íŠ¸ ë˜ëŠ” í¬ê¸° ê¸°ë°˜ íŒë‹¨
            checkpoint_size_gb = os.path.getsize(checkpoint_path) / (1024 ** 3)
            log_message(f"ğŸ“Š ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í¬ê¸°: {checkpoint_size_gb:.1f}GB")

            if checkpoint_size_gb > 3.0:  # í° ëª¨ë¸ (1.6 ë²„ì „ ì¶”ì •)
                model_version = "1.6"
                config_path = os.path.join(latentsync_dir, "configs", "unet", "stage2_512.yaml")
                if not os.path.exists(config_path):
                    config_path = os.path.join(latentsync_dir, "configs", "unet", "stage2.yaml")
                expected_vram = "18GB"
                inference_steps = "30"
                guidance_scale = "1.5"  # gradio_app.py ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€ê²½ (0.7 â†’ 1.5)
                log_message("ğŸ¯ LatentSync 1.6 ëª¨ë¸ ê°ì§€ (ê³ í•´ìƒë„ 512x512)")
            else:  # ì‘ì€ ëª¨ë¸ (1.5 ë²„ì „ ì¶”ì •)
                model_version = "1.5"
                config_path = os.path.join(latentsync_dir, "configs", "unet", "stage2.yaml")
                if not os.path.exists(config_path):
                    config_path = os.path.join(latentsync_dir, "configs", "unet", "stage2_efficient.yaml")
                expected_vram = "8GB"
                inference_steps = "15"
                guidance_scale = "1.0"
                log_message("ğŸ¯ LatentSync 1.5 ëª¨ë¸ ê°ì§€ (í‘œì¤€ 256x256)")

        if not os.path.exists(config_path):
            log_message(f"âŒ LatentSync ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        log_message(f"âš™ï¸ ëª¨ë¸ ë²„ì „: LatentSync {model_version}")
        log_message(f"âš™ï¸ ì‚¬ìš© ì„¤ì •: {os.path.basename(config_path)}")
        log_message(f"ğŸ’¾ ì˜ˆìƒ VRAM ìš”êµ¬ì‚¬í•­: {expected_vram} (ì¶”ë¡  ì‹œ)")

        # íŒŒë¼ë¯¸í„° ìµœì í™” (ë²„ì „ë³„ ìµœì í™”)
        log_message(f"ğŸ›ï¸ LatentSync ì¶”ë¡  íŒŒë¼ë¯¸í„° ({model_version} ë²„ì „ ìµœì í™”):")
        log_message(f"   - ì¶”ë¡  ë‹¨ê³„: {inference_steps}")
        log_message(f"   - ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼: {guidance_scale}")
        log_message(f"   - ì„¤ì • íŒŒì¼: {os.path.basename(config_path)}")
        log_message(f"   - DeepCache: í™œì„±í™” (ì†ë„ í–¥ìƒ)")

        # LatentSync ì¶”ë¡  ì‹¤í–‰ (ì „ì²˜ë¦¬ëœ ë¹„ë””ì˜¤ ì‚¬ìš©)
        latentsync_cmd = [
            "python", "-m", "scripts.inference",
            "--unet_config_path", config_path,
            "--inference_ckpt_path", checkpoint_path,
            "--video_path", abs_video_path,
            "--audio_path", os.path.abspath(audio_path),
            "--video_out_path", output_path,
            "--inference_steps", inference_steps,
            "--guidance_scale", guidance_scale,
            "--seed", "1247",
            "--enable_deepcache"  # ì†ë„ í–¥ìƒ
        ]

        # LatentSync ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
        result = subprocess.run(
            latentsync_cmd,
            cwd=latentsync_dir,
            capture_output=True,
            text=True,
            env=env
        )

        # LatentSync ì‹¤í–‰ ê²°ê³¼ ìƒì„¸ ë¡œê·¸
        log_message(f"ğŸ” LatentSync ì‹¤í–‰ ê²°ê³¼:")
        log_message(f"   ë°˜í™˜ ì½”ë“œ: {result.returncode}")

        if result.stdout:
            log_message(f"   í‘œì¤€ ì¶œë ¥:")
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    log_message(f"     {line}")

        if result.stderr:
            log_message(f"   ì˜¤ë¥˜ ì¶œë ¥:")
            for line in result.stderr.strip().split('\n'):
                if line.strip():
                    log_message(f"     {line}")

        if result.returncode != 0:
            log_message(f"âŒ LatentSync ì‹¤í–‰ ì‹¤íŒ¨:")
            log_message(f"   ë°˜í™˜ ì½”ë“œ: {result.returncode}")

            # ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ê´€ë ¨ ì—ëŸ¬ í™•ì¸
            error_output = result.stderr.lower()
            if "face not detected" in error_output or "runtime error" in error_output:
                log_message("ğŸ” ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ë¡œ ì¸í•œ ì˜¤ë¥˜ ë¶„ì„:")
                log_message("   ğŸ’¡ ê°€ëŠ¥í•œ í•´ê²° ë°©ë²•:")
                log_message("   1. ì…ë ¥ ë¹„ë””ì˜¤ì— ëª…í™•í•œ ì–¼êµ´ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
                log_message("   2. ë¹„ë””ì˜¤ í•´ìƒë„ê°€ ë„ˆë¬´ ë‚®ì§€ ì•Šì€ì§€ í™•ì¸ (ìµœì†Œ 256x256 ê¶Œì¥)")
                log_message("   3. ì–¼êµ´ì´ ë„ˆë¬´ ì‘ê±°ë‚˜ ì¸¡ë©´ì„ í–¥í•˜ê³  ìˆì§€ ì•Šì€ì§€ í™•ì¸")
                log_message("   4. ì¡°ëª…ì´ ë„ˆë¬´ ì–´ë‘¡ê±°ë‚˜ ë°ì§€ ì•Šì€ì§€ í™•ì¸")
                log_message("   5. ì–¼êµ´ì´ ê°€ë ¤ì§€ê±°ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ë³´ì´ì§€ ì•ŠëŠ”ì§€ í™•ì¸")

                # ì›ë³¸ ë¹„ë””ì˜¤ë¡œ ëŒ€ì²´ ì¶œë ¥ ìƒì„± (ë¦½ì‹±í¬ ì—†ì´)
                log_message("ğŸ”„ ë¦½ì‹±í¬ ì—†ì´ ì˜¤ë””ì˜¤ì™€ ë¹„ë””ì˜¤ í•©ì„±ìœ¼ë¡œ ëŒ€ì²´...")
                try:
                    # ì›ë³¸ ë¹„ë””ì˜¤ì™€ ìƒˆ ì˜¤ë””ì˜¤ í•©ì„±
                    fallback_cmd = [
                        "ffmpeg", "-y", "-i", abs_video_path, "-i", os.path.abspath(audio_path),
                        "-c:v", "copy", "-c:a", "aac", "-map", "0:v:0", "-map", "1:a:0",
                        "-shortest", output_path
                    ]

                    fallback_result = subprocess.run(fallback_cmd, capture_output=True, text=True)
                    if fallback_result.returncode == 0:
                        log_message("âœ… ëŒ€ì²´ ì²˜ë¦¬ ì™„ë£Œ (ë¦½ì‹±í¬ ì—†ìŒ)")
                        log_message(f"   ğŸ“ ì¶œë ¥: {output_path}")
                        return True
                    else:
                        log_message("âŒ ëŒ€ì²´ ì²˜ë¦¬ë„ ì‹¤íŒ¨")
                except Exception as e:
                    log_message(f"âŒ ëŒ€ì²´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                log_message("   ğŸ’¡ ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:")
                log_message("   1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: ë‹¤ë¥¸ GPU í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
                log_message("   2. CUDA ì˜¤ë¥˜: nvidia-smië¡œ GPU ìƒíƒœ í™•ì¸")
                log_message("   3. ì˜ì¡´ì„± ë¬¸ì œ: LatentSync í™˜ê²½ ì¬ì„¤ì •")

            if not result.stderr and not result.stdout:
                log_message("   ì¶œë ¥ ì—†ìŒ - í™˜ê²½ ì„¤ì • ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            return False

        log_message("âœ… LatentSync ì²˜ë¦¬ ì™„ë£Œ")

        # ê²°ê³¼ íŒŒì¼ í™•ì¸
        if not os.path.exists(output_path):
            log_message(f"âŒ LatentSync ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
            log_message(f"   ì˜ˆìƒ ê²½ë¡œ: {output_path}")

            # temp ë””ë ‰í† ë¦¬ í™•ì¸
            temp_dir = os.path.join(latentsync_dir, "temp")
            if os.path.exists(temp_dir):
                try:
                    temp_files = os.listdir(temp_dir)
                    log_message(f"   temp ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼: {temp_files}")
                except:
                    log_message("   temp ë””ë ‰í† ë¦¬ ì ‘ê·¼ ë¶ˆê°€")
            return False

        log_message(f"âœ… ë¦½ì‹±í¬ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {os.path.basename(output_path)}")

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            if os.path.exists(video_path):
                os.remove(video_path)
                log_message("ğŸ—‘ï¸ 25fps ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except:
            log_message("âš ï¸ 25fps ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨")

        log_message(f"âœ… ë¦½ì‹±í¬ ì™„ë£Œ!")
        log_message(f"   ğŸ“ ìµœì¢… ìœ„ì¹˜: {output_path}")
        log_message(f"   ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / (1024 * 1024):.1f}MB")
        return True

    except Exception as e:
        log_message(f"âŒ ë¦½ì‹±í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        log_message(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def process_complete_pipeline(input_file, settings):
    """
    ì™„ì „í•œ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

    í”Œë¡œìš°:
    1. ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œ
    2. ìŒì„±ì—ì„œ ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬
    3. ë³´ì»¬ë§Œ STT â†’ ë²ˆì—­ â†’ TTS â†’ ë³‘í•©
    4. ì²˜ë¦¬ëœ ë³´ì»¬ê³¼ ë°°ê²½ìŒ ì¬í•©ì„±
    5. ìµœì¢… ì˜ìƒê³¼ ìŒì„± í•©ì„±
    """
    try:
        # ë””ë²„ê¹…: ì„¤ì • í™•ì¸
        log_message(f"ğŸ”§ ì²˜ë¦¬ ì„¤ì • í™•ì¸:")
        log_message(f"  - ë¦½ì‹±í¬ í™œì„±í™”: {settings.get('enable_lip_sync', False)}")
        log_message(f"  - ì„ íƒëœ ì–¸ì–´: {settings.get('selected_languages', [])}")

        base_name = os.path.splitext(os.path.basename(input_file))[0]
        output_base_dir = os.path.join(os.getcwd(), 'video_output', base_name)
        os.makedirs(output_base_dir, exist_ok=True)

        log_message(f"ğŸ¬ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {input_file}")

        # Step 1: ì˜ìƒ ì²˜ë¦¬ (ìŒì„± ì¶”ì¶œ + ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬)
        log_message("ğŸ“¹ Step 1: ì˜ìƒì—ì„œ ìŒì„± ì¶”ì¶œ ë° ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬")
        extracted_audio, vocals_path, background_path, original_video = process_video_file(
            input_file, output_base_dir
        )

        if not vocals_path or not background_path:
            log_message("âŒ ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬ ì‹¤íŒ¨, íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
            return

        # Step 2: ë³´ì»¬ íŒŒì¼ë¡œ STT ì²˜ë¦¬
        log_message("ğŸ¤ Step 2: ë³´ì»¬ ìŒì„±ìœ¼ë¡œ STT ì²˜ë¦¬")
        vad_config = load_vad_config()
        output_dir, segments, orig_duration = run_full_whisper_processing(vocals_path, vad_config)

        if not output_dir or not segments:
            log_message("âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨, íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
            return

        # í™”ì ê¸°ë°˜ ë¶„ë¦¬ ì ìš© (í™œì„±í™”ëœ ê²½ìš°)
        if settings.get('enable_speaker_splitting', False):
            log_message("ğŸ—£ï¸ í™”ì ê¸°ë°˜ ë¶„ë¦¬ ì ìš© ì¤‘...")
            base_name = os.path.splitext(os.path.basename(vocals_path))[0]
            srt_path = os.path.join(output_dir, f"{base_name}{os.path.splitext(vocals_path)[1]}.srt")
            segments, orig_duration = apply_speaker_based_splitting(
                vocals_path,
                srt_path,
                output_dir,
                True
            )

        if not output_dir or not segments:
            log_message("âŒ í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # Step 3: í…ìŠ¤íŠ¸ ë²ˆì—­ ë° ìŒì„± í•©ì„±
        log_message("ğŸ”„ Step 3: í…ìŠ¤íŠ¸ ë²ˆì—­ ë° ìŒì„± í•©ì„±")

        # ë²ˆì—­ ì„¤ì • êµ¬ì„±
        translation_settings = {
            'translation_length': settings.get('translation_length', 0.8),
            'quality_mode': settings.get('quality_mode', 'balanced'),
            'selected_languages': settings.get('selected_languages', ['english'])
        }

        # Whisper ë””ë ‰í† ë¦¬ ì²˜ë¦¬ (ë²ˆì—­ í¬í•¨)
        selected_languages = run_whisper_directory(output_dir, translation_settings)

        if not selected_languages:
            log_message("âŒ ë²ˆì—­ ì²˜ë¦¬ ì‹¤íŒ¨, íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
            return

        # ê° ì–¸ì–´ë³„ë¡œ ìŒì„± í•©ì„±
        log_message("ğŸ”Š ê° ì–¸ì–´ë³„ë¡œ ìŒì„± í•©ì„± ì‹œì‘...")

        processed_vocals = {}

        for lang in selected_languages:
            lang_name = SUPPORTED_LANGUAGES[lang]['name'].lower()
            trans_type = "free"
            text_dir = os.path.join(output_dir, 'txt', lang_name, trans_type)

            if not os.path.exists(text_dir):
                log_message(f"â­ï¸ {SUPPORTED_LANGUAGES[lang]['name']} {trans_type} í…ìŠ¤íŠ¸ ì—†ìŒ, ê±´ë„ˆë›°ê¸°")
                continue

            log_message(f"ğŸ”Š {SUPPORTED_LANGUAGES[lang]['name']} ({trans_type}) ìŒì„± í•©ì„± ì‹œì‘...")

            # CosyVoice2 í•©ì„± í˜¸ì¶œ
            cosy_out = os.path.join(output_dir, 'cosy_output', lang_name, trans_type)
            os.makedirs(cosy_out, exist_ok=True)

            # 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ (ì œë¡œìƒ· í•©ì„±ì„ ìœ„í•œ)
            if settings.get('enable_3sec_extension', True):
                log_message("ğŸ”„ ì œë¡œìƒ· í•©ì„±ì„ ìœ„í•œ 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì¤‘...")
                from audio_processor import extend_short_segments_for_zeroshot, create_extended_segments_mapping
                extended_wav_dir = extend_short_segments_for_zeroshot(output_dir, min_duration_ms=3000)

                if extended_wav_dir:
                    # í™•ì¥ ë§¤í•‘ ì •ë³´ ìƒì„±
                    mapping_info = create_extended_segments_mapping(output_dir, extended_wav_dir)
                    log_message(f"ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì™„ë£Œ: {len(mapping_info.get('segments_info', []))}ê°œ íŒŒì¼ ì²˜ë¦¬")

                    # í™•ì¥ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•©ì„±
                    synthesis_audio_dir = extended_wav_dir
                else:
                    # í™•ì¥ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                    log_message("âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì‹¤íŒ¨, ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©")
                    synthesis_audio_dir = os.path.join(output_dir, 'wav')
            else:
                # ì„¤ì • ë¹„í™œì„±í™” ì‹œ ì›ë³¸ ì‚¬ìš©
                synthesis_audio_dir = os.path.join(output_dir, 'wav')

            # ë©”ëª¨ë¦¬ ì •ë¦¬ (í•©ì„± ì „)
            import gc
            gc.collect()

            try:
                # UI ì„¤ì •ê°’ ì ìš©
                enable_instruct = settings.get('enable_instruct', False)
                manual_command = settings.get('manual_command', None)

                log_message(f"  ì–¸ì–´: {SUPPORTED_LANGUAGES[lang]['name']}")
                log_message(f"  ë²ˆì—­ ìœ í˜•: {trans_type}")
                log_message(f"  Instruct2 í™œì„±í™”: {enable_instruct}")
                if manual_command:
                    log_message(f"  ìˆ˜ë™ ëª…ë ¹ì–´: {manual_command}")

                # CosyVoice2 ë°°ì¹˜ í•©ì„± (ì–¸ì–´ ì •ë³´ í¬í•¨)
                cosy_batch(
                    audio_dir=synthesis_audio_dir,
                    prompt_text_dir=os.path.join(output_dir, 'txt', 'ko'),
                    text_dir=text_dir,
                    out_dir=cosy_out,
                    enable_instruct=enable_instruct,
                    manual_command=manual_command,
                    target_language=lang
                )

                log_message(f"âœ… {lang_name} ({trans_type}) í•©ì„± ì™„ë£Œ")

                # ì‹¤ì œ í•©ì„± íŒŒì¼ë“¤ì€ zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ì— ì €ì¥ë¨
                actual_synthesis_dir = os.path.join(cosy_out, 'zero_shot')

                # ë³‘í•©
                merged_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_merged.wav")
                merge_segments_preserve_timing(
                    segments,
                    orig_duration,  # ì´ë¯¸ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ì´ë¯€ë¡œ * 1000 ì œê±°
                    actual_synthesis_dir,  # zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ ì°¸ì¡°
                    merged_path,
                    length_handling=settings.get('length_handling', 'preserve'),
                    overlap_handling=settings.get('overlap_handling', 'fade'),
                    max_extension=settings.get('max_extension', 50),
                    enable_smart_compression=settings.get('enable_smart_compression', True)
                )

                processed_vocals[lang] = merged_path
                log_message(f"âœ… {lang_name} ë³´ì»¬ ë³‘í•© ì™„ë£Œ: {merged_path}")

            except Exception as e:
                log_message(f"âŒ {SUPPORTED_LANGUAGES[lang]['name']} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue

            # í•©ì„± ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()

        # Step 4: ê° ì–¸ì–´ë³„ë¡œ ë³´ì»¬+ë°°ê²½ìŒ í•©ì„± ë° ìµœì¢… ì˜ìƒ ìƒì„±
        log_message("ğŸµ Step 4: ë³´ì»¬ê³¼ ë°°ê²½ìŒ í•©ì„± ë° ìµœì¢… ì˜ìƒ ìƒì„±")

        final_videos = []

        for lang_code, processed_vocal_path in processed_vocals.items():
            lang_name = SUPPORTED_LANGUAGES[lang_code]['name'].lower()
            lang_display_name = SUPPORTED_LANGUAGES[lang_code]['name']

            # ë³´ì»¬ + ë°°ê²½ìŒ í•©ì„±
            combined_audio_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_combined.wav")

            success = combine_processed_audio_with_background(
                processed_vocal_path,
                background_path,
                combined_audio_path,
                vocals_volume=settings.get('vocals_volume', 1.0),
                background_volume=settings.get('background_volume', 0.8)
            )

            if success:
                # ìµœì¢… ì˜ìƒ ìƒì„±
                final_video_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_final.mp4")

                video_success = combine_audio_with_video(
                    original_video,
                    combined_audio_path,
                    final_video_path
                )

                if video_success:
                    final_videos.append((lang_name, final_video_path))
                    log_message(f"âœ… {lang_name} ìµœì¢… ì˜ìƒ ì™„ë£Œ: {final_video_path}")
                else:
                    log_message(f"âŒ {lang_name} ì˜ìƒ í•©ì„± ì‹¤íŒ¨")
            else:
                log_message(f"âŒ {lang_name} ìŒì„± í•©ì„± ì‹¤íŒ¨")

        # Step 5: ë¦½ì‹±í¬ ì²˜ë¦¬ (ëª¨ë“  ì–¸ì–´ì— ëŒ€í•´)
        if settings.get('enable_lip_sync', False):
            log_message("ğŸ—£ï¸ ë¦½ì‹±í¬ ì²˜ë¦¬ í™œì„±í™”ë¨. ëª¨ë“  ì–¸ì–´ ë²„ì „ì— ë¦½ì‹±í¬ ì ìš© ì¤‘...")
            log_message(f"   ğŸ¯ ì²˜ë¦¬ ëŒ€ìƒ ì–¸ì–´: {len(processed_vocals)}ê°œ")

            # ë””ë²„ê¹…: processed_vocals ë‚´ìš© í™•ì¸
            if processed_vocals:
                log_message("   ğŸ“ ì²˜ë¦¬ëœ ì–¸ì–´ ëª©ë¡:")
                for lang_code, vocal_path in processed_vocals.items():
                    lang_name = SUPPORTED_LANGUAGES.get(lang_code, {}).get('name', lang_code)
                    log_message(f"     - {lang_name} ({lang_code}): {vocal_path}")
            else:
                log_message("   âš ï¸ ì²˜ë¦¬ëœ ì–¸ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:")
                log_message("     1. ë²ˆì—­ ì²˜ë¦¬ê°€ ì„±ê³µí–ˆëŠ”ì§€")
                log_message("     2. CosyVoice í•©ì„±ì´ ì„±ê³µí–ˆëŠ”ì§€")
                log_message("     3. ìŒì„± ë³‘í•©ì´ ì„±ê³µí–ˆëŠ”ì§€")
                log_message("   ğŸ“‹ ì„ íƒëœ ì–¸ì–´ ëª©ë¡:")
                for lang in selected_languages:
                    lang_name = SUPPORTED_LANGUAGES.get(lang, {}).get('name', lang)
                    log_message(f"     - {lang_name} ({lang})")

            lip_sync_videos = []

            for idx, (lang_code, processed_vocal_path) in enumerate(processed_vocals.items(), 1):
                lang_name = SUPPORTED_LANGUAGES[lang_code]['name'].lower()
                lang_display_name = SUPPORTED_LANGUAGES[lang_code]['name']

                # í•´ë‹¹ ì–¸ì–´ì˜ ê¸°ë³¸ ìµœì¢… ì˜ìƒ ê²½ë¡œ
                regular_video_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_final.mp4")

                # ë¦½ì‹±í¬ìš© ì¶œë ¥ ê²½ë¡œ ìƒì„±
                lip_sync_output_path = os.path.join(output_base_dir, f"{base_name}_{lang_name}_final_lipsynced.mp4")

                log_message(f"ğŸ¬ [{idx}/{len(processed_vocals)}] {lang_display_name} ë¦½ì‹±í¬ ì²˜ë¦¬ ì‹œì‘...")
                log_message(f"   ğŸ“¹ ê¸°ë³¸ ì˜ìƒ: {os.path.basename(regular_video_path)}")
                log_message(f"   ğŸµ ìŒì„± íŒŒì¼: {os.path.basename(processed_vocal_path)}")

                # ê¸°ë³¸ ì˜ìƒì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                if not os.path.exists(regular_video_path):
                    log_message(f"âŒ {lang_display_name} ê¸°ë³¸ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
                    log_message(f"   ê²½ë¡œ: {regular_video_path}")
                    continue

                # ìŒì„± íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                if not os.path.exists(processed_vocal_path):
                    log_message(f"âŒ {lang_display_name} ì²˜ë¦¬ëœ ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
                    log_message(f"   ê²½ë¡œ: {processed_vocal_path}")
                    continue

                # ë¦½ì‹±í¬ ì²˜ë¦¬ (ê¸°ë³¸ ì˜ìƒ + í•´ë‹¹ ì–¸ì–´ ìŒì„±)
                log_message(f"âš™ï¸ {lang_display_name} LatentSync ì²˜ë¦¬ ì¤‘...")
                start_time = time.time()

                if apply_lip_sync_to_video(regular_video_path, processed_vocal_path, lip_sync_output_path):
                    end_time = time.time()
                    processing_time = int(end_time - start_time)

                    lip_sync_videos.append((lang_name, lip_sync_output_path))
                    log_message(f"âœ… {lang_display_name} ë¦½ì‹±í¬ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {processing_time}ì´ˆ)")
                    log_message(f"   ğŸ’¾ ì¶œë ¥: {os.path.basename(lip_sync_output_path)}")
                else:
                    end_time = time.time()
                    processing_time = int(end_time - start_time)
                    log_message(f"âŒ {lang_display_name} ë¦½ì‹±í¬ ì²˜ë¦¬ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {processing_time}ì´ˆ)")

                # ì§„í–‰ë¥  í‘œì‹œ
                if len(processed_vocals) > 1:
                    progress_percent = (idx / len(processed_vocals)) * 100
                    log_message(f"ğŸ“Š ë¦½ì‹±í¬ ì§„í–‰ë¥ : {progress_percent:.1f}% ({idx}/{len(processed_vocals)})")

            # ë¦½ì‹±í¬ ê²°ê³¼ ìš”ì•½
            if lip_sync_videos:
                log_message("ğŸ‰ ëª¨ë“  ì–¸ì–´ ë¦½ì‹±í¬ ì˜ìƒ ìƒì„± ì™„ë£Œ:")
                log_message(f"   âœ… ì„±ê³µ: {len(lip_sync_videos)}ê°œ")
                log_message(f"   âŒ ì‹¤íŒ¨: {len(processed_vocals) - len(lip_sync_videos)}ê°œ")
                for lang_name, video_path in lip_sync_videos:
                    log_message(f"   ğŸ—£ï¸ {lang_name} ë¦½ì‹±í¬: {os.path.basename(video_path)}")
            else:
                log_message("âŒ ëª¨ë“  ì–¸ì–´ ë¦½ì‹±í¬ ì˜ìƒ ìƒì„± ì‹¤íŒ¨")
                log_message("   ì›ì¸: ê¸°ë³¸ ì˜ìƒ ë˜ëŠ” ìŒì„± íŒŒì¼ ëˆ„ë½, LatentSync ì²˜ë¦¬ ì˜¤ë¥˜ ë“±")

                # ì¶”ê°€ ë””ë²„ê¹… ì •ë³´
                log_message("   ğŸ” ë””ë²„ê¹… ì •ë³´:")
                log_message(f"     - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_base_dir}")
                log_message(f"     - ê¸°ë³¸ íŒŒì¼ëª…: {base_name}")

                # ì¶œë ¥ ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ í™•ì¸
                if os.path.exists(output_base_dir):
                    output_files = os.listdir(output_base_dir)
                    log_message(f"     - ì¶œë ¥ ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼: {len(output_files)}ê°œ")
                    for file in output_files[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                        log_message(f"       * {file}")
                    if len(output_files) > 5:
                        log_message(f"       ... ë° {len(output_files) - 5}ê°œ ë”")
                else:
                    log_message("     - ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")

        # ì™„ë£Œ ë©”ì‹œì§€
        if final_videos:
            log_message("ğŸ‰ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            log_message("ğŸ“ ìƒì„±ëœ ìµœì¢… ì˜ìƒë“¤:")
            for lang_name, video_path in final_videos:
                log_message(f"   ğŸ¬ {lang_name} (ê¸°ë³¸): {video_path}")

            # ë¦½ì‹±í¬ ì˜ìƒì´ ìˆë‹¤ë©´ í•¨ê»˜ í‘œì‹œ
            if settings.get('enable_lip_sync', False) and 'lip_sync_videos' in locals() and lip_sync_videos:
                log_message("ğŸ“ ìƒì„±ëœ ë¦½ì‹±í¬ ì˜ìƒë“¤:")
                for lang_name, video_path in lip_sync_videos:
                    log_message(f"   ğŸ—£ï¸ {lang_name} (ë¦½ì‹±í¬): {os.path.basename(video_path)}")
        else:
            log_message("âŒ ìµœì¢… ì˜ìƒ ìƒì„± ì‹¤íŒ¨")
            log_message("   ğŸ” ì‹¤íŒ¨ ì›ì¸ ë¶„ì„:")
            log_message(f"     - ì„ íƒëœ ì–¸ì–´ ìˆ˜: {len(selected_languages) if 'selected_languages' in locals() else 0}")
            log_message(f"     - ì²˜ë¦¬ëœ ë³´ì»¬ ìˆ˜: {len(processed_vocals) if 'processed_vocals' in locals() else 0}")
            log_message(f"     - ìµœì¢… ì˜ìƒ ìˆ˜: {len(final_videos) if 'final_videos' in locals() else 0}")

            # ê° ë‹¨ê³„ë³„ ìƒíƒœ í™•ì¸
            if 'selected_languages' in locals() and selected_languages:
                log_message("     âœ… ë²ˆì—­ ì²˜ë¦¬ ì™„ë£Œ")
            else:
                log_message("     âŒ ë²ˆì—­ ì²˜ë¦¬ ì‹¤íŒ¨")

            if 'processed_vocals' in locals() and processed_vocals:
                log_message("     âœ… ìŒì„± í•©ì„± ì™„ë£Œ")
            else:
                log_message("     âŒ ìŒì„± í•©ì„± ì‹¤íŒ¨")

        if not settings.get('enable_lip_sync', False):
            log_message("ğŸ—£ï¸ ë¦½ì‹±í¬ ì²˜ë¦¬ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        log_message(f"ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        log_message(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")


def process_audio_only_pipeline(input_file, settings):
    """ê¸°ì¡´ ìŒì„± íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ì›ë³¸ ê¸°ëŠ¥ ìœ ì§€)"""
    try:
        log_message("ğŸµ ìŒì„± íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")

        vad_config = load_vad_config()
        output_dir, segments, orig_duration = run_full_whisper_processing(input_file, vad_config)

        if not output_dir or not segments:
            log_message("âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # í™”ì ê¸°ë°˜ ë¶„ë¦¬ ì ìš© (í™œì„±í™”ëœ ê²½ìš°)
        if settings.get('enable_speaker_splitting', False):
            log_message("ğŸ—£ï¸ í™”ì ê¸°ë°˜ ë¶„ë¦¬ ì ìš© ì¤‘...")
            base_name = os.path.splitext(os.path.basename(input_file))[0]
            srt_path = os.path.join(output_dir, f"{base_name}{os.path.splitext(input_file)[1]}.srt")
            segments, total_duration = apply_speaker_based_splitting(
                input_file,
                srt_path,
                output_dir,
                True
            )
        else:
            base_name = os.path.splitext(os.path.basename(input_file))[0]
            srt_path = os.path.join(output_dir, f"{base_name}{os.path.splitext(input_file)[1]}.srt")
            segments = parse_srt_segments(srt_path)
            orig_audio = AudioSegment.from_file(input_file)
            original_duration_ms = len(orig_audio)

        if not output_dir or not segments:
            log_message("âŒ í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # ë²ˆì—­ ì„¤ì • êµ¬ì„±
        translation_settings = {
            'translation_length': settings.get('translation_length', 0.8),
            'quality_mode': settings.get('quality_mode', 'balanced'),
            'selected_languages': settings.get('selected_languages', ['english'])
        }

        # Whisper ë””ë ‰í† ë¦¬ ì²˜ë¦¬ (ë²ˆì—­ í¬í•¨)
        selected_languages = run_whisper_directory(output_dir, translation_settings)

        if not selected_languages:
            log_message("âŒ ë²ˆì—­ ì²˜ë¦¬ ì‹¤íŒ¨")
            return

        # ê° ì–¸ì–´ë³„ë¡œ ìŒì„± í•©ì„± ë° ë³‘í•©
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        input_ext = os.path.splitext(input_file)[1]
        srt_path = os.path.join(output_dir, f"{base_name}{input_ext}.srt")
        segments = parse_srt_segments(srt_path)
        orig_audio = AudioSegment.from_file(input_file)
        original_duration_ms = len(orig_audio)

        for lang in selected_languages:
            lang_name = SUPPORTED_LANGUAGES[lang]['name'].lower()
            trans_type = "free"
            text_dir = os.path.join(output_dir, 'txt', lang_name, trans_type)

            if not os.path.exists(text_dir):
                continue

            cosy_out = os.path.join(output_dir, 'cosy_output', lang_name, trans_type)
            os.makedirs(cosy_out, exist_ok=True)

            # 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ (ì œë¡œìƒ· í•©ì„±ì„ ìœ„í•œ)
            if settings.get('enable_3sec_extension', True):
                log_message("ğŸ”„ ì œë¡œìƒ· í•©ì„±ì„ ìœ„í•œ 3ì´ˆ ë¯¸ë§Œ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì¤‘...")
                from audio_processor import extend_short_segments_for_zeroshot, create_extended_segments_mapping
                extended_wav_dir = extend_short_segments_for_zeroshot(output_dir, min_duration_ms=3000)

                if extended_wav_dir:
                    # í™•ì¥ ë§¤í•‘ ì •ë³´ ìƒì„±
                    mapping_info = create_extended_segments_mapping(output_dir, extended_wav_dir)
                    log_message(f"ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì™„ë£Œ: {len(mapping_info.get('segments_info', []))}ê°œ íŒŒì¼ ì²˜ë¦¬")

                    # í™•ì¥ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•©ì„±
                    synthesis_audio_dir = extended_wav_dir
                else:
                    # í™•ì¥ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                    log_message("âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ í™•ì¥ ì‹¤íŒ¨, ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ìš©")
                    synthesis_audio_dir = os.path.join(output_dir, 'wav')
            else:
                # ì„¤ì • ë¹„í™œì„±í™” ì‹œ ì›ë³¸ ì‚¬ìš©
                synthesis_audio_dir = os.path.join(output_dir, 'wav')

            # CosyVoice2 í•©ì„±
            try:
                cosy_batch(
                    audio_dir=synthesis_audio_dir,
                    prompt_text_dir=os.path.join(output_dir, 'txt', 'ko'),
                    text_dir=text_dir,
                    out_dir=cosy_out,
                    enable_instruct=settings.get('enable_instruct', False),
                    manual_command=settings.get('manual_command', None),
                    target_language=lang
                )

                log_message(f"âœ… {lang_name} ({trans_type}) í•©ì„± ì™„ë£Œ")

                # ì‹¤ì œ í•©ì„± íŒŒì¼ë“¤ì€ zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ì— ì €ì¥ë¨
                actual_synthesis_dir = os.path.join(cosy_out, 'zero_shot')

                # ë³‘í•©
                merged_path = os.path.join(output_dir, f"{base_name}_{lang_name}_merged.wav")
                merge_segments_preserve_timing(
                    segments,
                    original_duration_ms,
                    actual_synthesis_dir,  # zero_shot ì„œë¸Œë””ë ‰í† ë¦¬ ì°¸ì¡°
                    merged_path,
                    length_handling=settings.get('length_handling', 'preserve'),
                    overlap_handling=settings.get('overlap_handling', 'fade'),
                    max_extension=settings.get('max_extension', 50),
                    enable_smart_compression=settings.get('enable_smart_compression', True)
                )

                log_message(f"âœ… {lang_name} ì²˜ë¦¬ ì™„ë£Œ: {merged_path}")

            except Exception as e:
                log_message(f"âŒ {lang_name} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        log_message("ğŸµ ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")

    except Exception as e:
        log_message(f"ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")


def start_processing_with_settings(input_file, settings):
    """íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°"""

    def worker():
        try:
            if is_video_file(input_file):
                log_message("ğŸ¬ ì˜ìƒ íŒŒì¼ ê°ì§€ - ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
                process_complete_pipeline(input_file, settings)
            elif is_audio_file(input_file):
                log_message("ğŸµ ìŒì„± íŒŒì¼ ê°ì§€ - ìŒì„± ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
                process_audio_only_pipeline(input_file, settings)
            else:
                log_message("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
        except Exception as e:
            log_message(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    threading.Thread(target=worker, daemon=True).start()
